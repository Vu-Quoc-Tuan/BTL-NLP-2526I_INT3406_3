{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7rtdAJALCwJ"
      },
      "source": [
        "# config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzjAsnz1JvOW",
        "outputId": "7d6b6c5c-d4b1-4c4f-c63c-d5d0441c2964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter GitHub token (hidden): ··········\n",
            "200\n",
            "Vu-Quoc-Tuan\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import requests, json\n",
        "\n",
        "token = getpass(\"Enter GitHub token (hidden): \")\n",
        "\n",
        "r = requests.get(\"https://api.github.com/user\", headers={\"Authorization\": f\"token {token}\"})\n",
        "print(r.status_code)\n",
        "print(r.json().get(\"login\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sBwvWH0oKQos",
        "outputId": "be0100cc-045c-4269-dd27-cdf2ea55805b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'BTL-NLP-2526I_INT3406_3'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 122 (delta 47), reused 81 (delta 29), pack-reused 23 (from 2)\u001b[K\n",
            "Receiving objects: 100% (122/122), 77.02 MiB | 14.42 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "Updating files: 100% (27/27), done.\n"
          ]
        }
      ],
      "source": [
        "username = \"Vu-Quoc-Tuan\"\n",
        "repo_name = \"BTL-NLP-2526I_INT3406_3\"\n",
        "\n",
        "# Sử dụng biến token để xác thực trực tiếp trong URL\n",
        "!git clone https://{token}@github.com/{username}/{repo_name}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TN2ebbTWJ0HR",
        "outputId": "ff86bc5f-5445-4f60-a708-7f445a252ec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/BTL-NLP-2526I_INT3406_3\n",
            "/content/BTL-NLP-2526I_INT3406_3\n",
            "total 24\n",
            "drwxr-xr-x 5 root root 4096 Dec 16 11:38 .\n",
            "drwxr-xr-x 1 root root 4096 Dec 16 11:38 ..\n",
            "drwxr-xr-x 8 root root 4096 Dec 16 11:38 .git\n",
            "-rw-r--r-- 1 root root   25 Dec 16 11:38 README.md\n",
            "drwxr-xr-x 4 root root 4096 Dec 16 11:38 transformer_base\n",
            "drwxr-xr-x 4 root root 4096 Dec 16 11:38 vlsp-mt\n",
            "total 36\n",
            "drwxr-xr-x 4 root root  4096 Dec 16 11:38 .\n",
            "drwxr-xr-x 5 root root  4096 Dec 16 11:38 ..\n",
            "drwxr-xr-x 3 root root  4096 Dec 16 11:38 data\n",
            "-rw-r--r-- 1 root root     0 Dec 16 11:38 experiment_log.md\n",
            "-rw-r--r-- 1 root root   485 Dec 16 11:38 requirements.txt\n",
            "-rw-r--r-- 1 root root 13116 Dec 16 11:38 run.md\n",
            "drwxr-xr-x 2 root root  4096 Dec 16 11:38 scripts\n",
            "requirements found\n",
            "Python executable: /usr/bin/python3\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 2)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 3)) (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 4)) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.40.0 in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 7)) (4.57.3)\n",
            "Requirement already satisfied: accelerate>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 8)) (1.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 9)) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 10)) (5.29.5)\n",
            "Requirement already satisfied: peft>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 13)) (0.18.0)\n",
            "Collecting bitsandbytes>=0.43.0 (from -r vlsp-mt/requirements.txt (line 14))\n",
            "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: datasets>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 17)) (4.0.0)\n",
            "Collecting sacrebleu (from -r vlsp-mt/requirements.txt (line 20))\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jiwer (from -r vlsp-mt/requirements.txt (line 21))\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 24)) (5.1.2)\n",
            "Collecting datasketch (from -r vlsp-mt/requirements.txt (line 27))\n",
            "  Downloading datasketch-1.8.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 30)) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 31)) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 32)) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 33)) (1.6.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 36)) (0.23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 39)) (5.9.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r vlsp-mt/requirements.txt (line 3)) (11.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (0.70.16)\n",
            "Collecting portalocker (from sacrebleu->-r vlsp-mt/requirements.txt (line 20))\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu->-r vlsp-mt/requirements.txt (line 20)) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->-r vlsp-mt/requirements.txt (line 20))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu->-r vlsp-mt/requirements.txt (line 20)) (6.0.2)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer->-r vlsp-mt/requirements.txt (line 21)) (8.3.1)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer->-r vlsp-mt/requirements.txt (line 21))\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r vlsp-mt/requirements.txt (line 33)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r vlsp-mt/requirements.txt (line 33)) (3.6.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r vlsp-mt/requirements.txt (line 36)) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->-r vlsp-mt/requirements.txt (line 36)) (4.5.1)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb->-r vlsp-mt/requirements.txt (line 36)) (2.12.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r vlsp-mt/requirements.txt (line 36)) (2.47.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (3.13.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r vlsp-mt/requirements.txt (line 36)) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r vlsp-mt/requirements.txt (line 36)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r vlsp-mt/requirements.txt (line 36)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r vlsp-mt/requirements.txt (line 36)) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r vlsp-mt/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r vlsp-mt/requirements.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (1.22.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r vlsp-mt/requirements.txt (line 36)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (1.17.0)\n",
            "Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading datasketch-1.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.1/96.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: rapidfuzz, portalocker, colorama, sacrebleu, jiwer, datasketch, bitsandbytes\n",
            "Successfully installed bitsandbytes-0.49.0 colorama-0.4.6 datasketch-1.8.0 jiwer-4.0.0 portalocker-3.2.0 rapidfuzz-3.14.3 sacrebleu-2.5.1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/BTL-NLP-2526I_INT3406_3\n",
        "\n",
        "!pwd\n",
        "!ls -la\n",
        "!ls -la vlsp-mt\n",
        "!test -f vlsp-mt/requirements.txt && echo \"requirements found\" || echo \"requirements NOT found\"\n",
        "\n",
        "import sys\n",
        "print(\"Python executable:\", sys.executable)\n",
        "\n",
        "!{sys.executable} -m pip install -r vlsp-mt/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eleAhgayLH6A"
      },
      "source": [
        "# Run script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2MnSwH7YU0O"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDIBELveLUZ5",
        "outputId": "6bc7af1a-a352-4737-8b8f-5dede7e1184e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/BTL-NLP-2526I_INT3406_3/vlsp-mt\n"
          ]
        }
      ],
      "source": [
        "%cd vlsp-mt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qHR38nUWLpE3",
        "outputId": "92057182-ba5b-476e-af54-5de2028acf82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "VLSP Medical Translation Preprocessing\n",
            "============================================================\n",
            "\n",
            "Loading data from:\n",
            "  Source: data/raw/train.en.txt\n",
            "  Target: data/raw/train.vi.txt\n",
            "Loaded 500,000 pairs\n",
            "\n",
            "Cleaning...\n",
            "After cleaning: 500,000 pairs\n",
            "\n",
            "Filtering...\n",
            "After filtering: 487,989 pairs\n",
            "\n",
            "Deduplicating by 'both'...\n",
            "After dedup: 339,489 pairs\n",
            "\n",
            "Splitting (dev=1000, test=1000)...\n",
            "\n",
            "Train:\n",
            "  Pairs: 337,489\n",
            "  Src length: min=3, max=229, avg=21.3\n",
            "  Tgt length: min=3, max=256, avg=30.2\n",
            "\n",
            "Dev:\n",
            "  Pairs: 1,000\n",
            "  Src length: min=3, max=109, avg=21.6\n",
            "  Tgt length: min=4, max=193, avg=30.4\n",
            "\n",
            "Test:\n",
            "  Pairs: 1,000\n",
            "  Src length: min=3, max=113, avg=20.9\n",
            "  Tgt length: min=4, max=165, avg=29.9\n",
            "\n",
            "============================================================\n",
            "Preprocessing complete!\n",
            "Output saved to: data/clean\n",
            "============================================================\n",
            "Config saved to: data/clean/preprocess_config.json\n"
          ]
        }
      ],
      "source": [
        "!python scripts/preprocess_vlsp.py \\\n",
        "    --src_in data/raw/train.en.txt \\\n",
        "    --tgt_in data/raw/train.vi.txt \\\n",
        "    --out_dir data/clean \\\n",
        "    --min_len 3 \\\n",
        "    --max_len 256 \\\n",
        "    --max_ratio 3.0 \\\n",
        "    --dev_size 1000 \\\n",
        "    --test_size 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aJF_PsYCLZfa",
        "outputId": "20373a8f-e894-4ace-9e4f-99373465ba5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['============================================================',\n",
              " 'MinHash LSH Deduplication',\n",
              " '============================================================',\n",
              " '',\n",
              " 'Loading data...',\n",
              " 'Loaded 337,489 pairs',\n",
              " 'Preparing texts for hashing...',\n",
              " 'Building MinHash signatures (threshold=0.85, k=5)...',\n",
              " 'Using 12 workers for parallel processing...',\n",
              " '',\n",
              " 'Computing MinHash:   0% 0/337489 [00:00<?, ?it/s]',\n",
              " 'Computing MinHash:   0% 1/337489 [00:07<711:15:48,  7.59s/it]',\n",
              " 'Computing MinHash:   0% 1001/337489 [00:07<30:25, 184.29it/s]',\n",
              " 'Computing MinHash:   1% 4001/337489 [00:07<05:51, 948.10it/s]',\n",
              " 'Computing MinHash:   2% 6001/337489 [00:07<03:28, 1593.37it/s]',\n",
              " 'Computing MinHash:   3% 9001/337489 [00:08<01:56, 2821.40it/s]',\n",
              " 'Computing MinHash:   4% 12001/337489 [00:14<06:10, 878.40it/s]',\n",
              " 'Computing MinHash:   5% 16001/337489 [00:15<03:30, 1529.51it/s]',\n",
              " 'Computing MinHash:   6% 19001/337489 [00:15<02:27, 2161.16it/s]',\n",
              " 'Computing MinHash:   6% 21001/337489 [00:15<01:57, 2686.14it/s]',\n",
              " 'Computing MinHash:   7% 23001/337489 [00:15<01:32, 3408.26it/s]',\n",
              " 'Computing MinHash:   7% 24685/337489 [00:22<06:00, 867.09it/s] ',\n",
              " 'Computing MinHash:   8% 27001/337489 [00:22<04:16, 1209.21it/s]',\n",
              " 'Computing MinHash:   9% 30001/337489 [00:22<02:46, 1846.30it/s]',\n",
              " 'Computing MinHash:   9% 31403/337489 [00:22<02:20, 2185.61it/s]',\n",
              " 'Computing MinHash:  10% 33001/337489 [00:22<01:52, 2708.33it/s]',\n",
              " 'Computing MinHash:  10% 35001/337489 [00:23<01:24, 3574.58it/s]',\n",
              " 'Computing MinHash:  11% 36246/337489 [00:29<06:31, 769.00it/s] ',\n",
              " 'Computing MinHash:  11% 38001/337489 [00:29<04:38, 1075.02it/s]',\n",
              " 'Computing MinHash:  12% 40001/337489 [00:29<03:14, 1528.04it/s]',\n",
              " 'Computing MinHash:  12% 42001/337489 [00:29<02:18, 2132.97it/s]',\n",
              " 'Computing MinHash:  13% 44001/337489 [00:30<01:49, 2691.28it/s]',\n",
              " 'Computing MinHash:  14% 47001/337489 [00:30<01:14, 3922.88it/s]',\n",
              " 'Computing MinHash:  14% 48088/337489 [00:36<05:49, 829.10it/s] ',\n",
              " 'Computing MinHash:  15% 49001/337489 [00:36<04:55, 974.65it/s]',\n",
              " 'Computing MinHash:  15% 50001/337489 [00:37<04:11, 1145.21it/s]',\n",
              " 'Computing MinHash:  16% 54001/337489 [00:37<01:57, 2419.65it/s]',\n",
              " 'Computing MinHash:  17% 56001/337489 [00:37<01:41, 2765.82it/s]',\n",
              " 'Computing MinHash:  17% 59001/337489 [00:37<01:06, 4166.73it/s]',\n",
              " 'Computing MinHash:  18% 60549/337489 [00:43<04:48, 959.11it/s] ',\n",
              " 'Computing MinHash:  18% 61641/337489 [00:44<04:08, 1109.14it/s]',\n",
              " 'Computing MinHash:  19% 62522/337489 [00:44<03:45, 1218.76it/s]',\n",
              " 'Computing MinHash:  19% 64001/337489 [00:44<02:44, 1659.64it/s]',\n",
              " 'Computing MinHash:  20% 67001/337489 [00:44<01:32, 2909.37it/s]',\n",
              " 'Computing MinHash:  20% 68440/337489 [00:45<01:16, 3507.87it/s]',\n",
              " 'Computing MinHash:  21% 69754/337489 [00:45<01:04, 4155.58it/s]',\n",
              " 'Computing MinHash:  21% 70980/337489 [00:45<00:57, 4658.41it/s]',\n",
              " 'Computing MinHash:  21% 72065/337489 [00:51<06:46, 653.55it/s] ',\n",
              " 'Computing MinHash:  22% 74001/337489 [00:52<04:33, 962.72it/s]',\n",
              " 'Computing MinHash:  23% 76001/337489 [00:52<03:02, 1432.73it/s]',\n",
              " 'Computing MinHash:  23% 78001/337489 [00:52<02:06, 2058.92it/s]',\n",
              " 'Computing MinHash:  24% 80001/337489 [00:52<01:35, 2701.89it/s]',\n",
              " 'Computing MinHash:  24% 81001/337489 [00:52<01:25, 2989.87it/s]',\n",
              " 'Computing MinHash:  25% 84001/337489 [00:58<04:33, 926.40it/s] ',\n",
              " 'Computing MinHash:  25% 85001/337489 [00:59<03:57, 1062.99it/s]',\n",
              " 'Computing MinHash:  25% 86001/337489 [00:59<03:23, 1237.44it/s]',\n",
              " 'Computing MinHash:  26% 87001/337489 [00:59<02:48, 1489.65it/s]',\n",
              " 'Computing MinHash:  26% 89001/337489 [00:59<01:49, 2269.08it/s]',\n",
              " 'Computing MinHash:  27% 91001/337489 [00:59<01:17, 3178.39it/s]',\n",
              " 'Computing MinHash:  28% 93001/337489 [01:00<00:59, 4077.25it/s]',\n",
              " 'Computing MinHash:  28% 94001/337489 [01:00<00:53, 4556.45it/s]',\n",
              " 'Computing MinHash:  28% 96001/337489 [01:06<04:49, 835.38it/s] ',\n",
              " 'Computing MinHash:  29% 97001/337489 [01:06<04:11, 956.28it/s]',\n",
              " 'Computing MinHash:  29% 99001/337489 [01:06<02:47, 1423.93it/s]',\n",
              " 'Computing MinHash:  30% 100001/337489 [01:06<02:17, 1732.67it/s]',\n",
              " 'Computing MinHash:  30% 101001/337489 [01:07<01:56, 2032.85it/s]',\n",
              " 'Computing MinHash:  31% 104001/337489 [01:07<01:04, 3633.22it/s]',\n",
              " 'Computing MinHash:  31% 106001/337489 [01:07<00:51, 4460.84it/s]',\n",
              " 'Computing MinHash:  32% 108001/337489 [01:13<04:08, 922.23it/s] ',\n",
              " 'Computing MinHash:  32% 109001/337489 [01:14<03:48, 997.84it/s]',\n",
              " 'Computing MinHash:  33% 111001/337489 [01:14<02:46, 1362.66it/s]',\n",
              " 'Computing MinHash:  34% 116001/337489 [01:14<01:15, 2927.79it/s]',\n",
              " 'Computing MinHash:  35% 118001/337489 [01:14<01:01, 3567.55it/s]',\n",
              " 'Computing MinHash:  35% 119559/337489 [01:14<00:51, 4226.26it/s]',\n",
              " 'Computing MinHash:  36% 121062/337489 [01:21<04:02, 891.06it/s] ',\n",
              " 'Computing MinHash:  36% 123001/337489 [01:21<03:05, 1159.08it/s]',\n",
              " 'Computing MinHash:  37% 126001/337489 [01:21<01:54, 1841.93it/s]',\n",
              " 'Computing MinHash:  38% 129001/337489 [01:21<01:15, 2762.71it/s]',\n",
              " 'Computing MinHash:  39% 130613/337489 [01:22<01:03, 3235.07it/s]',\n",
              " 'Computing MinHash:  39% 131996/337489 [01:22<01:05, 3158.38it/s]',\n",
              " 'Computing MinHash:  39% 133051/337489 [01:28<04:33, 748.35it/s] ',\n",
              " 'Computing MinHash:  40% 134001/337489 [01:28<03:47, 893.73it/s]',\n",
              " 'Computing MinHash:  40% 135001/337489 [01:29<03:05, 1089.26it/s]',\n",
              " 'Computing MinHash:  40% 136001/337489 [01:29<02:28, 1357.80it/s]',\n",
              " 'Computing MinHash:  41% 140001/337489 [01:29<01:04, 3071.17it/s]',\n",
              " 'Computing MinHash:  42% 142001/337489 [01:29<00:51, 3807.18it/s]',\n",
              " 'Computing MinHash:  42% 143263/337489 [01:29<00:51, 3794.47it/s]',\n",
              " 'Computing MinHash:  43% 144259/337489 [01:35<03:55, 821.94it/s] ',\n",
              " 'Computing MinHash:  43% 145001/337489 [01:35<03:42, 866.82it/s]',\n",
              " 'Computing MinHash:  43% 146001/337489 [01:36<03:01, 1056.39it/s]',\n",
              " 'Computing MinHash:  44% 148001/337489 [01:36<01:56, 1620.72it/s]',\n",
              " 'Computing MinHash:  44% 149001/337489 [01:36<01:35, 1979.03it/s]',\n",
              " 'Computing MinHash:  45% 152001/337489 [01:36<00:54, 3404.19it/s]',\n",
              " 'Computing MinHash:  45% 153001/337489 [01:36<00:48, 3787.04it/s]',\n",
              " 'Computing MinHash:  46% 155001/337489 [01:37<00:40, 4547.72it/s]',\n",
              " 'Computing MinHash:  46% 156001/337489 [01:42<03:57, 762.98it/s] ',\n",
              " 'Computing MinHash:  47% 157001/337489 [01:43<03:27, 871.57it/s]',\n",
              " 'Computing MinHash:  47% 158001/337489 [01:43<02:43, 1098.99it/s]',\n",
              " 'Computing MinHash:  47% 160001/337489 [01:44<01:50, 1604.55it/s]',\n",
              " 'Computing MinHash:  49% 164001/337489 [01:44<00:52, 3299.18it/s]',\n",
              " 'Computing MinHash:  49% 165381/337489 [01:44<00:48, 3537.68it/s]',\n",
              " 'Computing MinHash:  49% 166493/337489 [01:44<00:46, 3651.88it/s]',\n",
              " 'Computing MinHash:  50% 167398/337489 [01:44<00:42, 4032.70it/s]',\n",
              " 'Computing MinHash:  50% 168256/337489 [01:50<03:59, 705.60it/s] ',\n",
              " 'Computing MinHash:  50% 169001/337489 [01:50<03:32, 791.05it/s]',\n",
              " 'Computing MinHash:  50% 170001/337489 [01:50<02:42, 1029.68it/s]',\n",
              " 'Computing MinHash:  51% 172001/337489 [01:50<01:39, 1663.19it/s]',\n",
              " 'Computing MinHash:  51% 173001/337489 [01:51<01:31, 1797.41it/s]',\n",
              " 'Computing MinHash:  52% 175001/337489 [01:51<00:57, 2820.28it/s]',\n",
              " 'Computing MinHash:  53% 178001/337489 [01:52<00:44, 3569.19it/s]',\n",
              " 'Computing MinHash:  53% 179001/337489 [01:52<00:39, 4017.34it/s]',\n",
              " 'Computing MinHash:  53% 180001/337489 [01:57<03:13, 811.87it/s] ',\n",
              " 'Computing MinHash:  54% 181001/337489 [01:57<02:51, 911.17it/s]',\n",
              " 'Computing MinHash:  54% 182001/337489 [01:58<02:16, 1136.88it/s]',\n",
              " 'Computing MinHash:  54% 183001/337489 [01:58<01:46, 1454.57it/s]',\n",
              " 'Computing MinHash:  55% 184001/337489 [01:58<01:28, 1733.97it/s]',\n",
              " 'Computing MinHash:  55% 185001/337489 [01:58<01:17, 1969.29it/s]',\n",
              " 'Computing MinHash:  56% 188001/337489 [01:58<00:37, 3971.87it/s]',\n",
              " 'Computing MinHash:  56% 189105/337489 [01:59<00:34, 4278.32it/s]',\n",
              " 'Computing MinHash:  56% 190053/337489 [01:59<00:34, 4255.93it/s]',\n",
              " 'Computing MinHash:  57% 192001/337489 [02:04<02:49, 856.45it/s] ',\n",
              " 'Computing MinHash:  57% 193001/337489 [02:05<02:33, 941.19it/s]',\n",
              " 'Computing MinHash:  57% 194001/337489 [02:05<02:03, 1164.37it/s]',\n",
              " 'Computing MinHash:  58% 195001/337489 [02:05<01:41, 1402.71it/s]',\n",
              " 'Computing MinHash:  58% 196001/337489 [02:06<01:36, 1461.87it/s]',\n",
              " 'Computing MinHash:  59% 200001/337489 [02:06<00:39, 3450.38it/s]',\n",
              " 'Computing MinHash:  60% 202001/337489 [02:06<00:33, 4011.93it/s]',\n",
              " 'Computing MinHash:  60% 203028/337489 [02:06<00:31, 4330.95it/s]',\n",
              " 'Computing MinHash:  60% 204001/337489 [02:11<02:34, 865.78it/s] ',\n",
              " 'Computing MinHash:  61% 205001/337489 [02:12<02:23, 924.50it/s]',\n",
              " 'Computing MinHash:  61% 206001/337489 [02:12<01:52, 1163.91it/s]',\n",
              " 'Computing MinHash:  61% 207001/337489 [02:13<01:37, 1334.14it/s]',\n",
              " 'Computing MinHash:  62% 208001/337489 [02:13<01:16, 1682.42it/s]',\n",
              " 'Computing MinHash:  62% 209001/337489 [02:13<01:06, 1946.14it/s]',\n",
              " 'Computing MinHash:  63% 213001/337489 [02:13<00:26, 4620.73it/s]',\n",
              " 'Computing MinHash:  64% 214346/337489 [02:14<00:27, 4524.13it/s]',\n",
              " 'Computing MinHash:  64% 215415/337489 [02:14<00:24, 4926.68it/s]',\n",
              " 'Computing MinHash:  64% 216389/337489 [02:19<02:29, 812.68it/s] ',\n",
              " 'Computing MinHash:  64% 217077/337489 [02:19<02:23, 838.93it/s]',\n",
              " 'Computing MinHash:  65% 218001/337489 [02:20<02:09, 923.98it/s]',\n",
              " 'Computing MinHash:  65% 219001/337489 [02:20<01:39, 1186.44it/s]',\n",
              " 'Computing MinHash:  65% 221001/337489 [02:20<00:57, 2033.52it/s]',\n",
              " 'Computing MinHash:  66% 222001/337489 [02:20<00:47, 2439.17it/s]',\n",
              " 'Computing MinHash:  67% 225001/337489 [02:21<00:26, 4282.77it/s]',\n",
              " 'Computing MinHash:  67% 226034/337489 [02:21<00:25, 4412.47it/s]',\n",
              " 'Computing MinHash:  67% 227001/337489 [02:21<00:25, 4387.43it/s]',\n",
              " 'Computing MinHash:  68% 228001/337489 [02:26<02:23, 765.07it/s] ',\n",
              " 'Computing MinHash:  68% 229001/337489 [02:26<02:01, 892.60it/s]',\n",
              " 'Computing MinHash:  68% 230001/337489 [02:27<01:49, 977.39it/s]',\n",
              " 'Computing MinHash:  68% 231001/337489 [02:27<01:25, 1251.86it/s]',\n",
              " 'Computing MinHash:  69% 232001/337489 [02:28<01:03, 1656.86it/s]',\n",
              " 'Computing MinHash:  69% 234001/337489 [02:28<00:37, 2728.94it/s]',\n",
              " 'Computing MinHash:  70% 237001/337489 [02:28<00:28, 3564.29it/s]',\n",
              " 'Computing MinHash:  71% 239001/337489 [02:28<00:20, 4696.58it/s]',\n",
              " 'Computing MinHash:  71% 240001/337489 [02:33<01:46, 914.75it/s] ',\n",
              " 'Computing MinHash:  71% 241001/337489 [02:34<01:29, 1075.24it/s]',\n",
              " 'Computing MinHash:  72% 242001/337489 [02:35<01:33, 1017.69it/s]',\n",
              " 'Computing MinHash:  72% 244001/337489 [02:35<00:59, 1567.16it/s]',\n",
              " 'Computing MinHash:  73% 246001/337489 [02:35<00:39, 2305.57it/s]',\n",
              " 'Computing MinHash:  73% 248001/337489 [02:35<00:27, 3278.00it/s]',\n",
              " 'Computing MinHash:  74% 249099/337489 [02:35<00:24, 3676.46it/s]',\n",
              " 'Computing MinHash:  74% 251001/337489 [02:36<00:21, 4025.31it/s]',\n",
              " 'Computing MinHash:  75% 252001/337489 [02:41<01:38, 865.48it/s] ',\n",
              " 'Computing MinHash:  75% 253001/337489 [02:41<01:24, 1000.58it/s]',\n",
              " 'Computing MinHash:  75% 254001/337489 [02:42<01:24, 988.50it/s] ',\n",
              " 'Computing MinHash:  76% 256001/337489 [02:42<00:52, 1550.16it/s]',\n",
              " 'Computing MinHash:  76% 257001/337489 [02:42<00:42, 1891.36it/s]',\n",
              " 'Computing MinHash:  77% 260001/337489 [02:43<00:22, 3463.21it/s]',\n",
              " 'Computing MinHash:  77% 261119/337489 [02:43<00:19, 3907.60it/s]',\n",
              " 'Computing MinHash:  78% 262131/337489 [02:43<00:17, 4230.74it/s]',\n",
              " 'Computing MinHash:  78% 263023/337489 [02:43<00:20, 3663.72it/s]',\n",
              " 'Computing MinHash:  78% 264001/337489 [02:48<01:37, 755.27it/s] ',\n",
              " 'Computing MinHash:  79% 265001/337489 [02:48<01:24, 857.95it/s]',\n",
              " 'Computing MinHash:  79% 266001/337489 [02:50<01:24, 846.81it/s]',\n",
              " 'Computing MinHash:  79% 268001/337489 [02:50<00:48, 1437.51it/s]',\n",
              " 'Computing MinHash:  80% 270001/337489 [02:50<00:31, 2109.66it/s]',\n",
              " 'Computing MinHash:  81% 273001/337489 [02:50<00:18, 3490.26it/s]',\n",
              " 'Computing MinHash:  81% 275001/337489 [02:51<00:16, 3796.54it/s]',\n",
              " 'Computing MinHash:  82% 276001/337489 [02:55<01:01, 1004.85it/s]',\n",
              " 'Computing MinHash:  82% 277001/337489 [02:56<00:56, 1063.46it/s]',\n",
              " 'Computing MinHash:  82% 278001/337489 [02:57<01:00, 990.18it/s] ',\n",
              " 'Computing MinHash:  83% 280001/337489 [02:57<00:37, 1546.06it/s]',\n",
              " 'Computing MinHash:  84% 283001/337489 [02:57<00:21, 2556.39it/s]',\n",
              " 'Computing MinHash:  84% 285001/337489 [02:58<00:17, 2962.15it/s]',\n",
              " 'Computing MinHash:  85% 288001/337489 [03:03<00:41, 1202.60it/s]',\n",
              " 'Computing MinHash:  86% 289001/337489 [03:03<00:37, 1282.92it/s]',\n",
              " 'Computing MinHash:  86% 290001/337489 [03:04<00:40, 1163.02it/s]',\n",
              " 'Computing MinHash:  87% 293001/337489 [03:05<00:22, 1949.07it/s]',\n",
              " 'Computing MinHash:  87% 295001/337489 [03:05<00:16, 2557.95it/s]',\n",
              " 'Computing MinHash:  88% 297001/337489 [03:05<00:11, 3398.44it/s]',\n",
              " 'Computing MinHash:  88% 298001/337489 [03:05<00:11, 3544.48it/s]',\n",
              " 'Computing MinHash:  89% 299001/337489 [03:05<00:10, 3671.81it/s]',\n",
              " 'Computing MinHash:  89% 300001/337489 [03:10<00:45, 823.26it/s] ',\n",
              " 'Computing MinHash:  89% 301001/337489 [03:10<00:37, 973.38it/s]',\n",
              " 'Computing MinHash:  89% 302001/337489 [03:12<00:39, 887.43it/s]',\n",
              " 'Computing MinHash:  90% 304001/337489 [03:12<00:22, 1457.01it/s]',\n",
              " 'Computing MinHash:  90% 305001/337489 [03:12<00:18, 1790.85it/s]',\n",
              " 'Computing MinHash:  91% 306001/337489 [03:12<00:15, 2073.85it/s]',\n",
              " 'Computing MinHash:  92% 309001/337489 [03:12<00:07, 3757.84it/s]',\n",
              " 'Computing MinHash:  92% 311001/337489 [03:13<00:07, 3675.47it/s]',\n",
              " 'Computing MinHash:  92% 312001/337489 [03:17<00:25, 981.30it/s] ',\n",
              " 'Computing MinHash:  93% 313001/337489 [03:17<00:20, 1182.30it/s]',\n",
              " 'Computing MinHash:  93% 314001/337489 [03:19<00:23, 1001.44it/s]',\n",
              " 'Computing MinHash:  93% 315001/337489 [03:19<00:17, 1290.25it/s]',\n",
              " 'Computing MinHash:  94% 317001/337489 [03:19<00:10, 2017.61it/s]',\n",
              " 'Computing MinHash:  94% 318001/337489 [03:19<00:08, 2316.56it/s]',\n",
              " 'Computing MinHash:  95% 320001/337489 [03:20<00:05, 3319.05it/s]',\n",
              " 'Computing MinHash:  95% 321001/337489 [03:20<00:04, 3460.48it/s]',\n",
              " 'Computing MinHash:  96% 323001/337489 [03:20<00:03, 3834.40it/s]',\n",
              " 'Computing MinHash:  96% 324001/337489 [03:25<00:15, 884.35it/s] ',\n",
              " 'Computing MinHash:  96% 325001/337489 [03:25<00:11, 1067.58it/s]',\n",
              " 'Computing MinHash:  97% 326001/337489 [03:26<00:12, 937.34it/s] ',\n",
              " 'Computing MinHash:  97% 328001/337489 [03:27<00:06, 1529.62it/s]',\n",
              " 'Computing MinHash:  98% 330001/337489 [03:27<00:03, 2222.94it/s]',\n",
              " 'Computing MinHash:  98% 332001/337489 [03:27<00:01, 3202.94it/s]',\n",
              " 'Computing MinHash:  99% 333023/337489 [03:27<00:01, 3320.03it/s]',\n",
              " 'Computing MinHash: 100% 336001/337489 [03:28<00:00, 4232.80it/s]',\n",
              " 'Computing MinHash: 100% 336772/337489 [03:29<00:00, 1933.10it/s]',\n",
              " 'Computing MinHash: 100% 337489/337489 [03:29<00:00, 1608.98it/s]',\n",
              " 'Building LSH index...',\n",
              " '',\n",
              " 'Indexing:   0% 0/337489 [00:00<?, ?it/s]',\n",
              " 'Indexing:   0% 1240/337489 [00:00<00:58, 5789.32it/s]',\n",
              " 'Indexing:   2% 6598/337489 [00:00<00:13, 24910.06it/s]',\n",
              " 'Indexing:   3% 11776/337489 [00:00<00:09, 34681.87it/s]',\n",
              " 'Indexing:   5% 17069/337489 [00:00<00:07, 40920.63it/s]',\n",
              " 'Indexing:   6% 21919/337489 [00:00<00:07, 43406.32it/s]',\n",
              " 'Indexing:   8% 26632/337489 [00:00<00:12, 24545.92it/s]',\n",
              " 'Indexing:   9% 31736/337489 [00:01<00:10, 29859.71it/s]',\n",
              " 'Indexing:  11% 36806/337489 [00:01<00:08, 34500.72it/s]',\n",
              " 'Indexing:  12% 41803/337489 [00:01<00:07, 38234.49it/s]',\n",
              " 'Indexing:  14% 46379/337489 [00:01<00:07, 39952.35it/s]',\n",
              " 'Indexing:  15% 50927/337489 [00:01<00:13, 21813.11it/s]',\n",
              " 'Indexing:  17% 55987/337489 [00:01<00:10, 26627.95it/s]',\n",
              " 'Indexing:  18% 60886/337489 [00:02<00:08, 30939.87it/s]',\n",
              " 'Indexing:  20% 65853/337489 [00:02<00:07, 34985.19it/s]',\n",
              " 'Indexing:  21% 70794/337489 [00:02<00:06, 38385.66it/s]',\n",
              " 'Indexing:  22% 75757/337489 [00:02<00:06, 41217.37it/s]',\n",
              " 'Indexing:  24% 80746/337489 [00:02<00:05, 43511.73it/s]',\n",
              " 'Indexing:  25% 85542/337489 [00:02<00:12, 19806.02it/s]',\n",
              " 'Indexing:  26% 89155/337489 [00:03<00:11, 22172.85it/s]',\n",
              " 'Indexing:  28% 94164/337489 [00:03<00:09, 27033.14it/s]',\n",
              " 'Indexing:  29% 99204/337489 [00:03<00:07, 31686.28it/s]',\n",
              " 'Indexing:  31% 104217/337489 [00:03<00:06, 35770.26it/s]',\n",
              " 'Indexing:  32% 109144/337489 [00:03<00:05, 39013.52it/s]',\n",
              " 'Indexing:  34% 114125/337489 [00:03<00:05, 41772.12it/s]',\n",
              " 'Indexing:  35% 119059/337489 [00:03<00:04, 43794.21it/s]',\n",
              " 'Indexing:  37% 123960/337489 [00:03<00:04, 45212.56it/s]',\n",
              " 'Indexing:  38% 128791/337489 [00:04<00:12, 17363.02it/s]',\n",
              " 'Indexing:  40% 133698/337489 [00:04<00:09, 21553.61it/s]',\n",
              " 'Indexing:  41% 138578/337489 [00:04<00:07, 25881.00it/s]',\n",
              " 'Indexing:  43% 143460/337489 [00:04<00:06, 30122.90it/s]',\n",
              " 'Indexing:  44% 148348/337489 [00:04<00:05, 34041.82it/s]',\n",
              " 'Indexing:  45% 153068/337489 [00:04<00:04, 37063.35it/s]',\n",
              " 'Indexing:  47% 157968/337489 [00:05<00:04, 40012.61it/s]',\n",
              " 'Indexing:  48% 162816/337489 [00:05<00:04, 42220.56it/s]',\n",
              " 'Indexing:  50% 167654/337489 [00:05<00:03, 43891.76it/s]',\n",
              " 'Indexing:  51% 172428/337489 [00:05<00:03, 44850.62it/s]',\n",
              " 'Indexing:  53% 177189/337489 [00:05<00:04, 37890.58it/s]',\n",
              " 'Indexing:  54% 181353/337489 [00:06<00:11, 13653.58it/s]',\n",
              " 'Indexing:  55% 186173/337489 [00:06<00:08, 17541.42it/s]',\n",
              " 'Indexing:  57% 191120/337489 [00:06<00:06, 21963.39it/s]',\n",
              " 'Indexing:  58% 196079/337489 [00:06<00:05, 26526.66it/s]',\n",
              " 'Indexing:  60% 200979/337489 [00:06<00:04, 30816.29it/s]',\n",
              " 'Indexing:  61% 205894/337489 [00:06<00:03, 34744.21it/s]',\n",
              " 'Indexing:  62% 210793/337489 [00:06<00:03, 38081.98it/s]',\n",
              " 'Indexing:  64% 215727/337489 [00:07<00:02, 40903.58it/s]',\n",
              " 'Indexing:  65% 220615/337489 [00:07<00:02, 42960.37it/s]',\n",
              " 'Indexing:  67% 225563/337489 [00:07<00:02, 44740.82it/s]',\n",
              " 'Indexing:  68% 230469/337489 [00:07<00:02, 45953.04it/s]',\n",
              " 'Indexing:  70% 235356/337489 [00:07<00:02, 46786.08it/s]',\n",
              " 'Indexing:  71% 240252/337489 [00:07<00:02, 47416.22it/s]',\n",
              " 'Indexing:  73% 245129/337489 [00:08<00:07, 12619.86it/s]',\n",
              " 'Indexing:  74% 250031/337489 [00:08<00:05, 16242.70it/s]',\n",
              " 'Indexing:  76% 254929/337489 [00:08<00:04, 20317.81it/s]',\n",
              " 'Indexing:  77% 259799/337489 [00:08<00:03, 24602.64it/s]',\n",
              " 'Indexing:  78% 264687/337489 [00:09<00:02, 28909.77it/s]',\n",
              " 'Indexing:  80% 269542/337489 [00:09<00:02, 32880.05it/s]',\n",
              " 'Indexing:  81% 274341/337489 [00:09<00:01, 36265.29it/s]',\n",
              " 'Indexing:  83% 279220/337489 [00:09<00:01, 39301.79it/s]',\n",
              " 'Indexing:  84% 284089/337489 [00:09<00:01, 41716.49it/s]',\n",
              " 'Indexing:  86% 288929/337489 [00:09<00:01, 43511.88it/s]',\n",
              " 'Indexing:  87% 293755/337489 [00:09<00:00, 44828.50it/s]',\n",
              " 'Indexing:  88% 298565/337489 [00:09<00:00, 45749.74it/s]',\n",
              " 'Indexing:  90% 303374/337489 [00:09<00:00, 46409.71it/s]',\n",
              " 'Indexing:  91% 308186/337489 [00:09<00:00, 46906.21it/s]',\n",
              " 'Indexing:  93% 312995/337489 [00:10<00:00, 47168.16it/s]',\n",
              " 'Indexing:  94% 317802/337489 [00:10<00:00, 47432.38it/s]',\n",
              " 'Indexing:  96% 322604/337489 [00:10<00:00, 47531.47it/s]',\n",
              " 'Indexing:  97% 327399/337489 [00:11<00:00, 10371.85it/s]',\n",
              " 'Indexing:  98% 332174/337489 [00:11<00:00, 13535.90it/s]',\n",
              " 'Indexing: 100% 336953/337489 [00:11<00:00, 17231.15it/s]',\n",
              " 'Indexing: 100% 337489/337489 [00:11<00:00, 28769.44it/s]',\n",
              " 'Finding duplicate clusters...',\n",
              " '',\n",
              " 'Clustering:   0% 0/337489 [00:00<?, ?it/s]',\n",
              " 'Clustering:   2% 6820/337489 [00:00<00:04, 68195.02it/s]',\n",
              " 'Clustering:   4% 13671/337489 [00:00<00:04, 68378.04it/s]',\n",
              " 'Clustering:   6% 20509/337489 [00:00<00:04, 68339.61it/s]',\n",
              " 'Clustering:   8% 27343/337489 [00:00<00:04, 68256.30it/s]',\n",
              " 'Clustering:  10% 34169/337489 [00:00<00:04, 67836.99it/s]',\n",
              " 'Clustering:  12% 40954/337489 [00:00<00:04, 67771.97it/s]',\n",
              " 'Clustering:  14% 47761/337489 [00:00<00:04, 67867.31it/s]',\n",
              " 'Clustering:  16% 54548/337489 [00:00<00:04, 67823.62it/s]',\n",
              " 'Clustering:  18% 61331/337489 [00:00<00:04, 67805.71it/s]',\n",
              " 'Clustering:  20% 68112/337489 [00:01<00:03, 67550.85it/s]',\n",
              " 'Clustering:  22% 74868/337489 [00:01<00:03, 67429.91it/s]',\n",
              " 'Clustering:  24% 81612/337489 [00:01<00:03, 67387.13it/s]',\n",
              " 'Clustering:  26% 88351/337489 [00:01<00:03, 67127.97it/s]',\n",
              " 'Clustering:  28% 95065/337489 [00:01<00:03, 66902.02it/s]',\n",
              " 'Clustering:  30% 101756/337489 [00:01<00:03, 66395.29it/s]',\n",
              " 'Clustering:  32% 108397/337489 [00:01<00:03, 66226.91it/s]',\n",
              " 'Clustering:  34% 115021/337489 [00:01<00:03, 66037.28it/s]',\n",
              " 'Clustering:  36% 121626/337489 [00:01<00:03, 65939.77it/s]',\n",
              " 'Clustering:  38% 128221/337489 [00:01<00:03, 65638.98it/s]',\n",
              " 'Clustering:  40% 134786/337489 [00:02<00:03, 65340.84it/s]',\n",
              " 'Clustering:  42% 141321/337489 [00:02<00:03, 64964.07it/s]',\n",
              " 'Clustering:  44% 147818/337489 [00:02<00:02, 64640.48it/s]',\n",
              " 'Clustering:  46% 154283/337489 [00:02<00:02, 64243.25it/s]',\n",
              " 'Clustering:  48% 160708/337489 [00:02<00:02, 63979.99it/s]',\n",
              " 'Clustering:  50% 167107/337489 [00:02<00:02, 63819.47it/s]',\n",
              " 'Clustering:  51% 173490/337489 [00:02<00:02, 63699.01it/s]',\n",
              " 'Clustering:  53% 179860/337489 [00:02<00:02, 63383.40it/s]',\n",
              " 'Clustering:  55% 186199/337489 [00:02<00:02, 63216.02it/s]',\n",
              " 'Clustering:  57% 192521/337489 [00:02<00:02, 63079.68it/s]',\n",
              " 'Clustering:  59% 198829/337489 [00:03<00:02, 62730.60it/s]',\n",
              " 'Clustering:  61% 205103/337489 [00:03<00:02, 62443.68it/s]',\n",
              " 'Clustering:  63% 211348/337489 [00:03<00:02, 62341.56it/s]',\n",
              " 'Clustering:  64% 217583/337489 [00:03<00:01, 62081.35it/s]',\n",
              " 'Clustering:  66% 223792/337489 [00:03<00:01, 61881.45it/s]',\n",
              " 'Clustering:  68% 229981/337489 [00:03<00:01, 61410.26it/s]',\n",
              " 'Clustering:  70% 236123/337489 [00:03<00:01, 61362.69it/s]',\n",
              " 'Clustering:  72% 242260/337489 [00:03<00:01, 61334.21it/s]',\n",
              " 'Clustering:  74% 248418/337489 [00:03<00:01, 61404.54it/s]',\n",
              " 'Clustering:  75% 254559/337489 [00:03<00:01, 61380.40it/s]',\n",
              " 'Clustering:  77% 260698/337489 [00:04<00:01, 61244.63it/s]',\n",
              " 'Clustering:  79% 266824/337489 [00:04<00:01, 61247.84it/s]',\n",
              " 'Clustering:  81% 272949/337489 [00:04<00:01, 61231.91it/s]',\n",
              " 'Clustering:  83% 279073/337489 [00:04<00:00, 61225.44it/s]',\n",
              " 'Clustering:  85% 285196/337489 [00:04<00:00, 60963.22it/s]',\n",
              " 'Clustering:  86% 291293/337489 [00:04<00:00, 60844.26it/s]',\n",
              " 'Clustering:  88% 297382/337489 [00:04<00:00, 60854.60it/s]',\n",
              " 'Clustering:  90% 303468/337489 [00:04<00:00, 60800.31it/s]',\n",
              " 'Clustering:  92% 309549/337489 [00:04<00:00, 60584.35it/s]',\n",
              " 'Clustering:  94% 315608/337489 [00:04<00:00, 59943.62it/s]',\n",
              " 'Clustering:  95% 321616/337489 [00:05<00:00, 59982.68it/s]',\n",
              " 'Clustering:  97% 327618/337489 [00:05<00:00, 59992.53it/s]',\n",
              " 'Clustering:  99% 333623/337489 [00:05<00:00, 60008.89it/s]',\n",
              " 'Clustering: 100% 337489/337489 [00:05<00:00, 63569.43it/s]',\n",
              " '',\n",
              " '============================================================',\n",
              " 'DEDUPLICATION RESULTS',\n",
              " '============================================================',\n",
              " '  Original pairs:     337,489',\n",
              " '  Kept pairs:         333,823',\n",
              " '  Removed pairs:      3,666',\n",
              " '  Keep ratio:         98.91%',\n",
              " '  Number of clusters: 333,823',\n",
              " '  Avg cluster size:   1.01',\n",
              " '  Max cluster size:   15',\n",
              " '  Singleton clusters: 330,514',\n",
              " '============================================================',\n",
              " '',\n",
              " 'Saving deduplicated data...',\n",
              " '  Source: data/dedup/train.en',\n",
              " '  Target: data/dedup/train.vi',\n",
              " '  Metadata: data/dedup/dedup_meta.json']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!!python scripts/dedup_minhash.py \\\n",
        "    --src data/clean/train.en \\\n",
        "    --tgt data/clean/train.vi \\\n",
        "    --out_dir data/dedup \\\n",
        "    --threshold 0.85 \\\n",
        "    --dedup_by both \\\n",
        "    --rep_strategy longest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h9AV-Z2L4gq",
        "outputId": "3d4f2681-279d-4172-f876-b6bba7449323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 3.2M\n",
            "-rw-r--r-- 1 root root 1.4M Dec 16 11:42 en.txt\n",
            "-rw-r--r-- 1 root root 1.8M Dec 16 11:42 vi.txt\n"
          ]
        }
      ],
      "source": [
        "# 1. Tạo thư mục đích trước\n",
        "!mkdir -p data/rl_subset\n",
        "\n",
        "# 2. Chạy lệnh cắt file\n",
        "!head -n 50000 data/dedup/train.en > data/rl_subset/en.txt\n",
        "!head -n 50000 data/dedup/train.vi > data/rl_subset/vi.txt\n",
        "\n",
        "!ls -lh data/rl_subset/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu97wU9yYhNd"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zFkkMbgJMSlh",
        "outputId": "44855c60-b282-4276-f448-2a0f01337803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-16 11:43:14.921939: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-16 11:43:14.940811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765885394.962567    3925 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765885394.969326    3925 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765885394.986420    3925 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765885394.986452    3925 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765885394.986456    3925 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765885394.986458    3925 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-16 11:43:14.991499: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading tokenizer: Qwen/Qwen2.5-3B-Instruct\n",
            "tokenizer_config.json: 7.30kB [00:00, 32.2MB/s]\n",
            "vocab.json: 2.78MB [00:00, 114MB/s]\n",
            "merges.txt: 1.67MB [00:00, 135MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 181MB/s]\n",
            "Loading model: Qwen/Qwen2.5-3B-Instruct\n",
            "Using dtype: torch.bfloat16\n",
            "Flash Attention not installed, using SDPA\n",
            "config.json: 100% 661/661 [00:00<00:00, 4.53MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors.index.json: 35.6kB [00:00, 127MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/3.97G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/2.20G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 843k/2.20G [00:01<1:23:42, 438kB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 10.8M/2.20G [00:02<05:02, 7.25MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 1.75M/3.97G [00:02<1:20:37, 820kB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 709M/3.97G [00:02<00:07, 428MB/s]   \u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 982M/3.97G [00:02<00:05, 563MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   1% 29.1M/2.20G [00:02<02:09, 16.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   7% 151M/2.20G [00:02<00:17, 117MB/s]  \u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   9% 192M/2.20G [00:02<00:15, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  11% 244M/2.20G [00:02<00:11, 177MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.19G/3.97G [00:03<00:05, 465MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  14% 315M/2.20G [00:03<00:09, 201MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  20% 433M/2.20G [00:03<00:05, 319MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  24% 536M/2.20G [00:03<00:04, 398MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  28% 623M/2.20G [00:03<00:03, 431MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  34% 738M/2.20G [00:03<00:02, 555MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  40% 873M/2.20G [00:03<00:01, 712MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.34G/3.97G [00:04<00:08, 311MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  47% 1.04G/2.20G [00:04<00:01, 605MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.51G/3.97G [00:04<00:06, 375MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  56% 1.24G/2.20G [00:04<00:01, 740MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 1.67G/3.97G [00:04<00:05, 416MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 1.79G/3.97G [00:04<00:04, 486MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 1.97G/3.97G [00:04<00:03, 627MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  62% 1.37G/2.20G [00:04<00:01, 508MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.12G/3.97G [00:04<00:02, 732MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  66% 1.45G/2.20G [00:05<00:01, 451MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.24G/3.97G [00:05<00:02, 605MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  69% 1.52G/2.20G [00:05<00:01, 481MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  74% 1.62G/2.20G [00:05<00:01, 456MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.36G/3.97G [00:06<00:05, 314MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  77% 1.69G/2.20G [00:06<00:02, 236MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 2.45G/3.97G [00:06<00:05, 302MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 2.51G/3.97G [00:06<00:04, 297MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  80% 1.76G/2.20G [00:06<00:02, 207MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 2.61G/3.97G [00:06<00:03, 346MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 2.74G/3.97G [00:07<00:03, 404MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  83% 1.82G/2.20G [00:07<00:02, 177MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 2.83G/3.97G [00:07<00:02, 407MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  85% 1.87G/2.20G [00:07<00:01, 172MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 2.90G/3.97G [00:07<00:03, 317MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 2.94G/3.97G [00:07<00:03, 317MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  88% 1.94G/2.20G [00:09<00:03, 69.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.02G/3.97G [00:10<00:09, 96.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  97% 2.14G/2.20G [00:10<00:00, 148MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 2.20G/2.20G [00:10<00:00, 216MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 3.33G/3.97G [00:10<00:02, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 3.45G/3.97G [00:10<00:01, 335MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 3.65G/3.97G [00:10<00:00, 431MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 3.77G/3.97G [00:10<00:00, 430MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 3.90G/3.97G [00:11<00:00, 416MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 3.97G/3.97G [00:11<00:00, 347MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:11<00:00,  5.99s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.07it/s]\n",
            "generation_config.json: 100% 242/242 [00:00<00:00, 2.70MB/s]\n",
            "Gradient checkpointing DISABLED (faster but more VRAM)\n",
            "Trainable params: 59,867,136 (1.90%)\n",
            "Loading training data...\n",
            "Training samples: 333823\n",
            "Tokenizing train: 100% 333823/333823 [05:32<00:00, 1004.76 examples/s]\n",
            "Effective batch size: 32\n",
            "Steps per epoch: 10431\n",
            "Total steps: 10431\n",
            "NEFTune enabled with alpha=5.0\n",
            "/content/BTL-NLP-2526I_INT3406_3/vlsp-mt/scripts/train_qwen_lora.py:134: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `NEFTuneTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(**kwargs)\n",
            "\n",
            "============================================================\n",
            "Starting training...\n",
            "============================================================\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "{'loss': 4.5936, 'grad_norm': 23.79021644592285, 'learning_rate': 0.0, 'epoch': 0.0}\n",
            "{'loss': 2.6642, 'grad_norm': 4.0890583992004395, 'learning_rate': 0.0001996168582375479, 'epoch': 0.1}\n",
            "{'loss': 2.5247, 'grad_norm': 2.2845375537872314, 'learning_rate': 0.0001939934009992765, 'epoch': 0.2}\n",
            "{'loss': 2.4667, 'grad_norm': 2.1801910400390625, 'learning_rate': 0.0001766522235530403, 'epoch': 0.3}\n",
            "{'loss': 2.4292, 'grad_norm': 2.23821759223938, 'learning_rate': 0.0001500676061588592, 'epoch': 0.4}\n",
            "{'loss': 2.3841, 'grad_norm': 2.8438901901245117, 'learning_rate': 0.00011744536990099923, 'epoch': 0.5}\n",
            "{'loss': 2.6926, 'grad_norm': 2.0199997425079346, 'learning_rate': 8.271940825103777e-05, 'epoch': 0.6}\n",
            "{'loss': 2.3114, 'grad_norm': 2.0690510272979736, 'learning_rate': 5.007730150694154e-05, 'epoch': 0.7}\n",
            "{'loss': 2.2772, 'grad_norm': 1.8501849174499512, 'learning_rate': 2.3455339308823644e-05, 'epoch': 0.8}\n",
            "{'loss': 2.2552, 'grad_norm': 1.711802363395691, 'learning_rate': 6.063846125673222e-06, 'epoch': 0.9}\n",
            "{'loss': 2.2476, 'grad_norm': 1.8877032995224, 'learning_rate': 5.039251814720203e-11, 'epoch': 1.0}\n",
            "{'train_runtime': 11704.1816, 'train_samples_per_second': 28.522, 'train_steps_per_second': 0.891, 'train_loss': 2.425428049833131, 'epoch': 1.0}\n",
            "100% 10432/10432 [3:15:04<00:00,  1.12s/it]\n",
            "\n",
            "Saving adapter to runs/qwen_v2_1ep/lora_en2vi_sft\n",
            "\n",
            "============================================================\n",
            "Training complete!\n",
            "Adapter saved to: runs/qwen_v2_1ep/lora_en2vi_sft\n",
            "Metadata saved to: runs/qwen_v2_1ep/meta.json\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "!python scripts/train_qwen_lora.py \\\n",
        "  --model_name Qwen/Qwen2.5-3B-Instruct \\\n",
        "  --direction en2vi \\\n",
        "  --src data/dedup/train.en \\\n",
        "  --tgt data/dedup/train.vi \\\n",
        "  --run_id qwen_v2_1ep \\\n",
        "  --batch_size 32 \\\n",
        "  --grad_accum 1 \\\n",
        "  --epochs 1 \\\n",
        "  --neftune_alpha 5 \\\n",
        "  --no_grad_checkpoint \\\n",
        "  --label_smoothing 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uKL8a2LJMeGE",
        "outputId": "59b5c6b2-a066-403b-d0e1-5e974d8294ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-16 15:06:27.507985: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-16 15:06:27.526070: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765897587.548097   54428 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765897587.554691   54428 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765897587.571575   54428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765897587.571617   54428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765897587.571620   54428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765897587.571623   54428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-16 15:06:27.576632: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Using device: cuda\n",
            "Using SDPA\n",
            "Loading base model...\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.04it/s]\n",
            "Loading SFT adapter...\n",
            "Loading trainable model...\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.05it/s]\n",
            "Trainable params: 59,867,136\n",
            "Loaded RL data: 10000 pairs\n",
            "Epoch 1/1:   0% 0/625 [00:00<?, ?it/s]/content/BTL-NLP-2526I_INT3406_3/vlsp-mt/scripts/rl_train_grpo.py:77: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
            "Epoch 1/1: 100% 625/625 [2:11:51<00:00, 12.66s/it, loss=-0.6691, reward=0.4636, baseline=0.4865]\n",
            "\n",
            "Epoch 1 avg reward: 0.4877\n",
            "\n",
            "RL training completed!\n"
          ]
        }
      ],
      "source": [
        "!python scripts/rl_train_grpo.py \\\n",
        "    --model_name Qwen/Qwen2.5-3B-Instruct \\\n",
        "    --sft_adapter runs/qwen_v2_1ep/lora_en2vi_sft \\\n",
        "    --init_adapter runs/qwen_v2_1ep/lora_en2vi_sft \\\n",
        "    --rl_src data/rl_subset/en.txt \\\n",
        "    --rl_tgt data/rl_subset/vi.txt \\\n",
        "    --run_id qwen_rl_1ep \\\n",
        "    --direction en2vi \\\n",
        "    --batch_size 16 \\\n",
        "    --max_new_tokens 48"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVEdWvfNa5rg"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReGWjQNvMkeV",
        "outputId": "333a601b-0eaf-4ca6-9300-6f77b05026b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-16 17:19:33.700240: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-16 17:19:33.718200: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765905573.739827   87159 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765905573.746352   87159 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765905573.763225   87159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765905573.763264   87159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765905573.763267   87159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765905573.763270   87159 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-16 17:19:33.768284: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading model: Qwen/Qwen2.5-3B-Instruct\n",
            "Loading adapter: runs/qwen_v2_1ep/lora_en2vi_sft\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.08it/s]\n",
            "Model loaded on cuda:0, dtype=torch.bfloat16\n",
            "Loaded 1000 sentences from data/clean/dev.en\n",
            "Generating:   0% 0/125 [00:00<?, ?it/s]/content/BTL-NLP-2526I_INT3406_3/vlsp-mt/scripts/generate.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Generating: 100% 125/125 [20:32<00:00,  9.86s/it]\n",
            "\n",
            "Saved 1000 translations to outputs/dev.hyp.sft.vi\n"
          ]
        }
      ],
      "source": [
        "!python scripts/generate.py \\\n",
        "    --model_name Qwen/Qwen2.5-3B-Instruct \\\n",
        "    --adapter_path runs/qwen_v2_1ep/lora_en2vi_sft \\\n",
        "    --direction en2vi \\\n",
        "    --input data/clean/dev.en \\\n",
        "    --output outputs/dev.hyp.sft.vi \\\n",
        "    --batch_size 8 \\\n",
        "    --num_beams 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CUPimiQmMrcl",
        "outputId": "b6467a7d-23c6-46d7-de5b-a27da12eb77d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-16 17:43:21.965304: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-16 17:43:21.983499: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765907002.005031   93071 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765907002.011591   93071 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765907002.028560   93071 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765907002.028597   93071 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765907002.028600   93071 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765907002.028603   93071 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-16 17:43:22.033715: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading model: Qwen/Qwen2.5-3B-Instruct\n",
            "Loading adapter: runs/qwen_rl_1ep/final_model\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.07it/s]\n",
            "Model loaded on cuda:0, dtype=torch.bfloat16\n",
            "Loaded 1000 sentences from data/clean/dev.en\n",
            "Generating:   0% 0/125 [00:00<?, ?it/s]/content/BTL-NLP-2526I_INT3406_3/vlsp-mt/scripts/generate.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Generating: 100% 125/125 [20:37<00:00,  9.90s/it]\n",
            "\n",
            "Saved 1000 translations to outputs/dev.hyp.rl.vi\n"
          ]
        }
      ],
      "source": [
        "!python scripts/generate.py \\\n",
        "    --model_name Qwen/Qwen2.5-3B-Instruct \\\n",
        "    --adapter_path runs/qwen_rl_1ep/final_model \\\n",
        "    --direction en2vi \\\n",
        "    --input data/clean/dev.en \\\n",
        "    --output outputs/dev.hyp.rl.vi \\\n",
        "    --batch_size 8 \\\n",
        "    --num_beams 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcesgjccMs5g",
        "outputId": "4a09b734-69f8-4f42-b503-6852c8dbd8d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading hypothesis: outputs/dev.hyp.sft.vi\n",
            "Loading reference: data/clean/dev.vi\n",
            "\n",
            "Evaluating 1000 sentence pairs...\n",
            "\n",
            "==================================================\n",
            "EVALUATION RESULTS\n",
            "==================================================\n",
            "  BLEU:    50.55\n",
            "  chrF++:  64.65\n",
            "  chrF:    64.72\n",
            "  TER:     42.23 (lower is better)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "!python scripts/eval_bleu.py \\\n",
        "    --hyp outputs/dev.hyp.sft.vi \\\n",
        "    --ref data/clean/dev.vi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI78HtAcMv73",
        "outputId": "a4137b5b-c344-482d-9386-b7caa4079c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading hypothesis: outputs/dev.hyp.rl.vi\n",
            "Loading reference: data/clean/dev.vi\n",
            "\n",
            "Evaluating 1000 sentence pairs...\n",
            "\n",
            "==================================================\n",
            "EVALUATION RESULTS\n",
            "==================================================\n",
            "  BLEU:    50.59\n",
            "  chrF++:  64.70\n",
            "  chrF:    64.77\n",
            "  TER:     42.36 (lower is better)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "!python scripts/eval_bleu.py \\\n",
        "    --hyp outputs/dev.hyp.rl.vi \\\n",
        "    --ref data/clean/dev.vi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shC-JqgYrpu5"
      },
      "source": [
        "# Chạy public test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKls51l_UrvA",
        "outputId": "b024e6bc-3f93-4dde-b34e-c5cd32373c64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-16 18:17:29.690289: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-16 18:17:29.708809: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765909049.730949  101756 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765909049.737558  101756 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765909049.754743  101756 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765909049.754774  101756 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765909049.754777  101756 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765909049.754780  101756 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-16 18:17:29.759838: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading model: Qwen/Qwen2.5-3B-Instruct\n",
            "Loading adapter: runs/qwen_rl_1ep/final_model\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.07it/s]\n",
            "Model loaded on cuda:0, dtype=torch.bfloat16\n",
            "Loaded 3000 sentences from data/raw/public_test.en.txt\n",
            "Generating:   0% 0/375 [00:00<?, ?it/s]/content/BTL-NLP-2526I_INT3406_3/vlsp-mt/scripts/generate.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Generating: 100% 375/375 [1:01:35<00:00,  9.85s/it]\n",
            "\n",
            "Saved 3000 translations to outputs/public_test.hyp.rl.vi\n"
          ]
        }
      ],
      "source": [
        "!python scripts/generate.py \\\n",
        "    --model_name Qwen/Qwen2.5-3B-Instruct \\\n",
        "    --adapter_path runs/qwen_rl_1ep/final_model \\\n",
        "    --direction en2vi \\\n",
        "    --input data/raw/public_test.en.txt \\\n",
        "    --output outputs/public_test.hyp.rl.vi \\\n",
        "    --batch_size 8 \\\n",
        "    --num_beams 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcXFaeedUrnL",
        "outputId": "1577eb95-4b4d-4495-8c18-f447d0f22684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading hypothesis: outputs/public_test.hyp.rl.vi\n",
            "Loading reference: data/raw/public_test.vi.txt\n",
            "\n",
            "Evaluating 3000 sentence pairs...\n",
            "\n",
            "==================================================\n",
            "EVALUATION RESULTS\n",
            "==================================================\n",
            "  BLEU:    51.08\n",
            "  chrF++:  64.96\n",
            "  chrF:    65.11\n",
            "  TER:     41.72 (lower is better)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "!python scripts/eval_bleu.py \\\n",
        "    --hyp outputs/public_test.hyp.rl.vi \\\n",
        "    --ref data/raw/public_test.vi.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Khám phá Public test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqBeZFYyuw4n",
        "outputId": "0823ab6b-5a66-4064-e503-2d25d4b335e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kiến thức, thực hành sử dụng dịch vụ y tế công cộng của người có thẻ bảo hiểm y tế và các yếu tố ảnh hưởng tại Lào, Việt Nam\n",
            "Mô tả kiến thức, thực hành sử dụng dịch vụ y tế công cộng của người có thẻ bảo hiểm y tế và các yếu tố ảnh hưởng tại Lào PDR, Việt Nam năm 2017.\n",
            "Phương pháp nghiên cứu: Nghiên cứu cắt ngang được thực hiện trên 928 người có thẻ bảo hiểm y tế (BHYT) người trưởng thành tại 2 huyện Phone Hồng và Keo Oudom, tỉnh Lào.\n",
            "Kết quả: Tỷ lệ người có thẻ BHYT biết sử dụng dịch vụ y tế công cộng miễn phí lần đầu là 44,5% và được cung cấp thông tin BHYT là 34,8%.\n",
            "Tỷ lệ người mang thẻ BHYT đến cơ sở y tế công lập đầu tiên là 61,8%.\n",
            "Thực trạng kiến thức và thực hành của người có thẻ bảo hiểm y tế trong sử dụng dịch vụ khám chữa bệnh ở các cơ sở y tế công và một số yếu tố ảnh hưởng tại tỉnh Viêng Chăn, CHDCND Lào, năm 2017\n",
            "Mô tả thực trạng kiến thức, thực hành của người có thẻ bảo hiểm y tế trong sử dụng dịch vụ khám chữa bệnh ở các cơ sở y tế công và một số yếu tố liên quan tại tỉnh Viêng Chăn, Cộng hoà Dân chủ Nhân dân Lào năm 2017.\n",
            "Phương pháp: Thiết kế nghiên mô tả cắt ngang được thực hiện trên 928 người trưởng thành có thẻ bảo hiểm y tế tại 2 huyện Phone Hong và Keo Oudom, tỉnh Viêng Chăn.\n",
            "Kết quả: Tỷ lệ người biết được khám chữa bệnh (KCB) miễn phí tại nơi đăng ký ban đầu chiếm 44,5%, được cung cấp thông tin về bảo hiểm y tế (BHYT) chiếm 34,8%.\n",
            "Tỷ lệ người có thẻ BHYT thực hành khám chữa bệnh đúng nơi đăng ký KCB ban đầu chiếm 61,8%.\n",
            "Knowledge, practices in public health service utilization among health insurance card’s holders and influencing factors in Vientiane, Lao\n",
            "Describe knowledge, practices in public health service utilization among health insurance card's holders and influencing factors in Vientiane, Lao PDR, 2017.\n",
            "Methodology: A cross sectional study was used among 928 adult health insurance card's holders in Phone Hong and Keo Oudom districts, Vientiane province.\n",
            "Results: Percentage of card's holders who knew the finance-free utilization of the first registered public health services was 44.5% and being provided health insurance information was 34.8%.\n",
            "Percentage of card's holders who went to the first registered public health services was 61.8%.\n"
          ]
        }
      ],
      "source": [
        "!head -5 vlsp-mt/outputs/public_test.hyp.rl.vi\n",
        "!head -5 vlsp-mt/data/raw/public_test.vi.txt\n",
        "!head -5 vlsp-mt/data/raw/public_test.en.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQapo3zf3IIa",
        "outputId": "53a0c69d-ce7c-4469-ff91-5ee1b1bc1b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SRC ===\n",
            "Knowledge, practices in public health service utilization among health insurance card’s holders and influencing factors in Vientiane, Lao\n",
            "=== HYP ===\n",
            "Kiến thức, thực hành sử dụng dịch vụ y tế công cộng của người có thẻ bảo hiểm y tế và các yếu tố ảnh hưởng tại Lào, Việt Nam\n",
            "=== REF ===\n",
            "Thực trạng kiến thức và thực hành của người có thẻ bảo hiểm y tế trong sử dụng dịch vụ khám chữa bệnh ở các cơ sở y tế công và một số yếu tố ảnh hưởng tại tỉnh Viêng Chăn, CHDCND Lào, năm 2017\n",
            "=== SRC 500 ===\n",
            "Because of similar clinical manifestations and treatment therapies of Phechromocytoma and catecholaminessecreting Paraganglioma, clinicians use the term \"pheochromocytoma\" to refer to both of tumors.\n",
            "=== HYP 500 ===\n",
            "Do các biểu hiện lâm sàng và các liệu pháp điều trị tương tự của u tế bào ưa crom và u cận hạch tiết catecholamine, các bác sĩ lâm sàng sử dụng thuật ngữ\"pheochromocytoma\"để đề cập đến cả hai khối u.\n",
            "=== REF 500 ===\n",
            "Vì biểu hiện lâm sàng của hai nhóm bệnh PCC và PLG có tiết catecholamine tương tự nhau, phương pháp điều trị như nhau, nên trên lâm sàng thuật ngữ PCC (u tuỷ thượng thận) được dùng để chỉ cả 2 loại khối u.\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# 1. Check dòng đầu của unseen_v3 có khớp không\n",
        "!echo \"=== SRC ===\" && head -1 vlsp-mt/data/raw/test_unseen_v3.en.txt\n",
        "!echo \"=== HYP ===\" && head -1 vlsp-mt/outputs/test_unseen_v3.hyp.vi\n",
        "!echo \"=== REF ===\" && head -1 vlsp-mt/data/raw/test_unseen_v3.vi.txt\n",
        "\n",
        "# 2. Check dòng giữa file (dòng 500)\n",
        "!echo \"=== SRC 500 ===\" && sed -n '500p' vlsp-mt/data/raw/test_unseen_v3.en.txt\n",
        "!echo \"=== HYP 500 ===\" && sed -n '500p' vlsp-mt/outputs/test_unseen_v3.hyp.vi\n",
        "!echo \"=== REF 500 ===\" && sed -n '500p' vlsp-mt/data/raw/test_unseen_v3.vi.txt\n",
        "\n",
        "# 3. Confirm unseen thật sự không có trong train\n",
        "!head -1 vlsp-mt/data/raw/test_unseen_v3.en.txt | grep -Fx -f - vlsp-mt/data/raw/train.en.txt | wc -l\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76AS0hlU3h6t",
        "outputId": "38f1a8c9-65c3-4885-82f7-18b03e1bf0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading hypothesis: vlsp-mt/outputs/test_unseen_v3.hyp.vi\n",
            "Loading reference: vlsp-mt/data/raw/test_unseen_v3.vi.txt\n",
            "Loading source: vlsp-mt/data/raw/test_unseen_v3.en.txt\n",
            "\n",
            "Evaluating 1152 sentence pairs...\n",
            "\n",
            "Running Gemini evaluation (100 samples, batch_size=10)...\n",
            "  Using batching: 100 samples / 10 per batch = 10 API calls\n",
            "  Gemini eval: 10/100 (batch 1/10)\n",
            "  Gemini eval: 20/100 (batch 2/10)\n",
            "\n",
            "  DEBUG: Batch 3 error: Expecting value: line 1 column 1 (char 0)\n",
            "  Gemini eval: 30/100 (batch 3/10)\n",
            "  Gemini eval: 40/100 (batch 4/10)\n",
            "  Gemini eval: 50/100 (batch 5/10)\n",
            "  Gemini eval: 60/100 (batch 6/10)\n",
            "  Gemini eval: 70/100 (batch 7/10)\n",
            "  Gemini eval: 80/100 (batch 8/10)\n",
            "  Gemini eval: 90/100 (batch 9/10)\n",
            "  Gemini eval: 100/100 (batch 10/10)\n",
            "\n",
            "  === LOW SCORE SAMPLES (score <= 2): 17 ===\n",
            "\n",
            "  [Line 564] Score: 1\n",
            "    Reason: Wrong medical term: 'IM adrenalin' (intramuscular) was incorrectly translated as 'tiêm tĩnh mạch adrenalin' (intravenous), which is a critical medical error. Minor hallucination: Added 'trung bình' (average) for 'length of stay' which was not in the source.\n",
            "    SRC: The length of stay in the Pediatric Intensive Care Unit is seven days, with the need for mechanical ...\n",
            "    HYP: Thời gian nằm hồi sức trung bình là 7 ngày, thời gian thở máy kéo dài đến 24 giờ.Kết luận: Hầu hết c...\n",
            "    REF: Thời gian trung vị điều trị là 7 ngày, thời gian thở máy là 24 giờ.Kết luận: Hầu hết các bệnh nhân s...\n",
            "\n",
            "  [Line 210] Score: 1\n",
            "    Reason: Truncated and Omission: The translation is incomplete, abruptly cutting off the information for 'sodium benzoate' and entirely omitting the 'precision' and 'accuracy' details from the source.\n",
            "    SRC: The process was validated the system suitsability; selectivity; linearity range of naringin (10.0 - ...\n",
            "    HYP: Quy trình đã được thẩm định về tính phù hợp hệ thống; tính chọn lọc; khoảng tuyến tính của naringin ...\n",
            "    REF: Quy trình định lượng đạt các chỉ tiêu thẩm định gồm tính phù hợp hệ thống, độ đặc hiệu, khoảng tuyến...\n",
            "\n",
            "  [Line 779] Score: 2\n",
            "    Reason: Wrong medical term/Omission. 'adrenal incidentaloma' was translated as 'u tuyến thượng thận' (adrenal tumor), omitting the crucial 'incidentaloma' aspect, which should be 'phát hiện tình cờ'.\n",
            "    SRC: Keywords: Ganglioneuroma, adrenal incidentaloma.\n",
            "    HYP: Từ khoá: U hạch thần kinh, u tuyến thượng thận.\n",
            "    REF: Từ khoá: U hạch thần kinh, u thượng thận phát hiện tình cờ.\n",
            "\n",
            "  [Line 705] Score: 2\n",
            "    Reason: Wrong medical term/Awkward phrasing. 'fat impairment' was translated as 'suy nhược mỡ', which is not a standard medical term. 'Suy giảm mỡ' or 'thiếu hụt mỡ' would be more appropriate.\n",
            "    SRC: Among the 100 patients, 78% suffered from weight loss, 61% suffered from reduced appetite, 62% suffe...\n",
            "    HYP: Trong số 100 bệnh nhân, 78% bị giảm cân, 61% bị giảm cảm giác ngon miệng, 62% bị giảm hoạt động, 100...\n",
            "    REF: Trong 100 bệnh nhân nghiên cứu, 78% có giảm cân, 61% có ăn giảm, 62% bệnh nhân giảm hoạt động, 100% ...\n",
            "\n",
            "  [Line 941] Score: 2\n",
            "    Reason: Wrong medical term. 'dermis' was translated as 'lớp hạ bì' (hypodermis/subcutis) instead of 'lớp trung bì' (dermis). There's also some ambiguity in parsing the original complex sentence, but the 'dermis' error is clear.\n",
            "    SRC: In the patient group with bullous skin lesions, necrosis in the epidermis, bullous skin lesions betw...\n",
            "    HYP: Ở nhóm bệnh nhân có tổn thương da bọng nước, hoại tử ở lớp thượng bì, tổn thương da bọng nước giữa l...\n",
            "    REF: Với nhóm bệnh nhân có bọng nước: hay gặp hoại tử thượng bì, bọng nước giữa thượng bì-trung bì, xốp b...\n",
            "\n",
            "==================================================\n",
            "EVALUATION RESULTS\n",
            "==================================================\n",
            "  BLEU:    50.37\n",
            "  chrF++:  64.34\n",
            "  chrF:    64.52\n",
            "  TER:     42.74 (lower is better)\n",
            "  Gemini:  4.03/5.0 (100 samples)\n",
            "    Distribution: 1=10, 2=7, 3=16, 4=4, 5=63\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "!python vlsp-mt/scripts/eval_bleu.py --hyp vlsp-mt/outputs/test_unseen_v3.hyp.vi --ref vlsp-mt/data/raw/test_unseen_v3.vi.txt --src vlsp-mt/data/raw/test_unseen_v3.en.txt --no_meteor --gemini --gemini_api_key AIzaSyCI8PBr-UJAo_fdAe7ji1YgJi6IQ-NjvCU --gemini_verbose --gemini_samples 100 --gemini_batch_size 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTmxawkR_6dq",
        "outputId": "bde2ee01-c3d7-4ae7-d661-b5b3c1013a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading train vocab from: vlsp-mt/data/raw/train.en.txt\n",
            "  Train vocab size: 92,501 unique words\n",
            "  Train total tokens: 10,901,369\n",
            "\n",
            "Loading test vocab from: vlsp-mt/data/raw/test_unseen_v3.en.txt\n",
            "  Test vocab size: 4,427 unique words\n",
            "  Test total tokens: 25,605\n",
            "\n",
            "==================================================\n",
            "OOV ANALYSIS\n",
            "==================================================\n",
            "  OOV word types: 150 (3.4% of test vocab)\n",
            "  OOV tokens: 165 (0.6% of test tokens)\n",
            "\n",
            "  Top 30 OOV words (by frequency in test):\n",
            "      1. cd142                          (count: 3)\n",
            "      2. lci                            (count: 3)\n",
            "      3. ulva                           (count: 2)\n",
            "      4. hacor                          (count: 2)\n",
            "      5. willcoxon                      (count: 2)\n",
            "      6. signrank                       (count: 2)\n",
            "      7. retracts                       (count: 2)\n",
            "      8. pherochromocytomas             (count: 2)\n",
            "      9. c2h                            (count: 2)\n",
            "     10. lscs                           (count: 2)\n",
            "     11. contextof                      (count: 2)\n",
            "     12. gea                            (count: 2)\n",
            "     13. umbo                           (count: 2)\n",
            "     14. keo                            (count: 1)\n",
            "     15. oudom                          (count: 1)\n",
            "     16. precipating                    (count: 1)\n",
            "     17. hdlcholesterol                 (count: 1)\n",
            "     18. 14502                          (count: 1)\n",
            "     19. shreds                         (count: 1)\n",
            "     20. treasury                       (count: 1)\n",
            "     21. halimeda                       (count: 1)\n",
            "     22. mbh                            (count: 1)\n",
            "     23. labview                        (count: 1)\n",
            "     24. 8247                           (count: 1)\n",
            "     25. 8636                           (count: 1)\n",
            "     26. 8030                           (count: 1)\n",
            "     27. guna                           (count: 1)\n",
            "     28. suitsability                   (count: 1)\n",
            "     29. 9902                           (count: 1)\n",
            "     30. 34597x                         (count: 1)\n",
            "\n",
            "==================================================\n",
            "COVERAGE SUMMARY\n",
            "==================================================\n",
            "  Token coverage: 99.36%\n",
            "  (Higher is better - means more test words seen in training)\n"
          ]
        }
      ],
      "source": [
        "!python vlsp-mt/scripts/analyze_vocab.py --train vlsp-mt/data/raw/train.en.txt --test vlsp-mt/data/raw/test_unseen_v3.en.txt --top_oov 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzAn2hYhESbq",
        "outputId": "9037b29a-d5b0-45d7-c922-ba8d5cd471c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading train vocab from: vlsp-mt/data/raw/train.vi.txt\n",
            "  Train vocab size: 49,802 unique words\n",
            "  Train total tokens: 15,275,928\n",
            "\n",
            "Loading test vocab from: vlsp-mt/data/raw/test_unseen_v3.vi.txt\n",
            "  Test vocab size: 2,566 unique words\n",
            "  Test total tokens: 34,601\n",
            "\n",
            "==================================================\n",
            "OOV ANALYSIS\n",
            "==================================================\n",
            "  OOV word types: 81 (3.2% of test vocab)\n",
            "  OOV tokens: 91 (0.3% of test tokens)\n",
            "\n",
            "  Top 30 OOV words (by frequency in test):\n",
            "      1. nsnn                           (count: 3)\n",
            "      2. lci                            (count: 3)\n",
            "      3. ulva                           (count: 2)\n",
            "      4. hacor                          (count: 2)\n",
            "      5. willcoxon                      (count: 2)\n",
            "      6. signrank                       (count: 2)\n",
            "      7. α2cd142                        (count: 2)\n",
            "      8. plg                            (count: 2)\n",
            "      9. phone                          (count: 1)\n",
            "     10. oudom                          (count: 1)\n",
            "     11. cyclospron                     (count: 1)\n",
            "     12. 14502                          (count: 1)\n",
            "     13. pfize                          (count: 1)\n",
            "     14. toànbộ                         (count: 1)\n",
            "     15. 70oc                           (count: 1)\n",
            "     16. halimeda                       (count: 1)\n",
            "     17. labview                        (count: 1)\n",
            "     18. 8247                           (count: 1)\n",
            "     19. 8636                           (count: 1)\n",
            "     20. 8030                           (count: 1)\n",
            "     21. a1at                           (count: 1)\n",
            "     22. ple                            (count: 1)\n",
            "     23. guna                           (count: 1)\n",
            "     24. nữlà                           (count: 1)\n",
            "     25. 9902                           (count: 1)\n",
            "     26. 34597x                         (count: 1)\n",
            "     27. 35395x                         (count: 1)\n",
            "     28. oprd                           (count: 1)\n",
            "     29. thinpap                        (count: 1)\n",
            "     30. pigerd                         (count: 1)\n",
            "\n",
            "==================================================\n",
            "COVERAGE SUMMARY\n",
            "==================================================\n",
            "  Token coverage: 99.74%\n",
            "  (Higher is better - means more test words seen in training)\n"
          ]
        }
      ],
      "source": [
        "!python vlsp-mt/scripts/analyze_vocab.py --train vlsp-mt/data/raw/train.vi.txt --test vlsp-mt/data/raw/test_unseen_v3.vi.txt --top_oov 30\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
