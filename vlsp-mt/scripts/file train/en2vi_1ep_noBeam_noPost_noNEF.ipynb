{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7rtdAJALCwJ"
      },
      "source": [
        "# config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzjAsnz1JvOW",
        "outputId": "65aa32f0-125f-494c-d0bf-d5d48a27549d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter GitHub token (hidden): ··········\n",
            "200\n",
            "Vu-Quoc-Tuan\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import requests, json\n",
        "\n",
        "token = getpass(\"Enter GitHub token (hidden): \")\n",
        "\n",
        "r = requests.get(\"https://api.github.com/user\", headers={\"Authorization\": f\"token {token}\"})\n",
        "print(r.status_code)\n",
        "print(r.json().get(\"login\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBwvWH0oKQos",
        "outputId": "2f9007b6-31c2-41bd-c216-6b14d606e5ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'BTL-NLP-2526I_INT3406_3'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 67 (delta 23), reused 33 (delta 12), pack-reused 23 (from 2)\u001b[K\n",
            "Receiving objects: 100% (67/67), 47.83 MiB | 12.73 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ],
      "source": [
        "username = \"Vu-Quoc-Tuan\"\n",
        "repo_name = \"BTL-NLP-2526I_INT3406_3\"\n",
        "\n",
        "# Sử dụng biến token để xác thực trực tiếp trong URL\n",
        "!git clone https://{token}@github.com/{username}/{repo_name}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN2ebbTWJ0HR",
        "outputId": "a381bce2-6447-422a-a422-69e1ddb9e109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/BTL-NLP-2526I_INT3406_3\n",
            "/content/BTL-NLP-2526I_INT3406_3\n",
            "total 24\n",
            "drwxr-xr-x 5 root root 4096 Dec 15 08:38 .\n",
            "drwxr-xr-x 1 root root 4096 Dec 15 08:38 ..\n",
            "drwxr-xr-x 8 root root 4096 Dec 15 08:38 .git\n",
            "-rw-r--r-- 1 root root   25 Dec 15 08:38 README.md\n",
            "drwxr-xr-x 2 root root 4096 Dec 15 08:38 transformer_base\n",
            "drwxr-xr-x 4 root root 4096 Dec 15 08:38 vlsp-mt\n",
            "total 36\n",
            "drwxr-xr-x 4 root root  4096 Dec 15 08:38 .\n",
            "drwxr-xr-x 5 root root  4096 Dec 15 08:38 ..\n",
            "drwxr-xr-x 3 root root  4096 Dec 15 08:38 data\n",
            "-rw-r--r-- 1 root root     0 Dec 15 08:38 experiment_log.md\n",
            "-rw-r--r-- 1 root root   485 Dec 15 08:38 requirements.txt\n",
            "-rw-r--r-- 1 root root 13116 Dec 15 08:38 run.md\n",
            "drwxr-xr-x 2 root root  4096 Dec 15 08:38 scripts\n",
            "requirements found\n",
            "Python executable: /usr/bin/python3\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 2)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 3)) (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 4)) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.40.0 in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 7)) (4.57.3)\n",
            "Requirement already satisfied: accelerate>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 8)) (1.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 9)) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 10)) (5.29.5)\n",
            "Requirement already satisfied: peft>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 13)) (0.18.0)\n",
            "Collecting bitsandbytes>=0.43.0 (from -r vlsp-mt/requirements.txt (line 14))\n",
            "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: datasets>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 17)) (4.0.0)\n",
            "Collecting sacrebleu (from -r vlsp-mt/requirements.txt (line 20))\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jiwer (from -r vlsp-mt/requirements.txt (line 21))\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 24)) (5.1.2)\n",
            "Collecting datasketch (from -r vlsp-mt/requirements.txt (line 27))\n",
            "  Downloading datasketch-1.8.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 30)) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 31)) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 32)) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 33)) (1.6.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 36)) (0.23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from -r vlsp-mt/requirements.txt (line 39)) (5.9.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r vlsp-mt/requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r vlsp-mt/requirements.txt (line 3)) (11.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (0.70.16)\n",
            "Collecting portalocker (from sacrebleu->-r vlsp-mt/requirements.txt (line 20))\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu->-r vlsp-mt/requirements.txt (line 20)) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->-r vlsp-mt/requirements.txt (line 20))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu->-r vlsp-mt/requirements.txt (line 20)) (6.0.2)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer->-r vlsp-mt/requirements.txt (line 21)) (8.3.1)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer->-r vlsp-mt/requirements.txt (line 21))\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r vlsp-mt/requirements.txt (line 33)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r vlsp-mt/requirements.txt (line 33)) (3.6.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r vlsp-mt/requirements.txt (line 36)) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->-r vlsp-mt/requirements.txt (line 36)) (4.5.1)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb->-r vlsp-mt/requirements.txt (line 36)) (2.12.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r vlsp-mt/requirements.txt (line 36)) (2.47.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (3.13.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r vlsp-mt/requirements.txt (line 36)) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r vlsp-mt/requirements.txt (line 36)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r vlsp-mt/requirements.txt (line 36)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r vlsp-mt/requirements.txt (line 36)) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0->-r vlsp-mt/requirements.txt (line 7)) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r vlsp-mt/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r vlsp-mt/requirements.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (1.22.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r vlsp-mt/requirements.txt (line 36)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.18.0->-r vlsp-mt/requirements.txt (line 17)) (1.17.0)\n",
            "Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading datasketch-1.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.1/96.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: rapidfuzz, portalocker, colorama, sacrebleu, jiwer, datasketch, bitsandbytes\n",
            "Successfully installed bitsandbytes-0.49.0 colorama-0.4.6 datasketch-1.8.0 jiwer-4.0.0 portalocker-3.2.0 rapidfuzz-3.14.3 sacrebleu-2.5.1\n"
          ]
        }
      ],
      "source": [
        "# 1) vào thư mục repo (thay path nếu khác)\n",
        "%cd /content/BTL-NLP-2526I_INT3406_3\n",
        "\n",
        "# 2) kiểm tra hiện tại đang ở đâu và liệt kê file\n",
        "!pwd\n",
        "!ls -la\n",
        "!ls -la vlsp-mt\n",
        "!test -f vlsp-mt/requirements.txt && echo \"requirements found\" || echo \"requirements NOT found\"\n",
        "\n",
        "# 3) show python interpreter đang dùng\n",
        "import sys\n",
        "print(\"Python executable:\", sys.executable)\n",
        "\n",
        "# 4) dùng chính interpreter đó để cài (an toàn hơn dùng !pip trực tiếp)\n",
        "!{sys.executable} -m pip install -r vlsp-mt/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eleAhgayLH6A"
      },
      "source": [
        "# Run script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSZP7thFJ-AL",
        "outputId": "1c90fef1-b8a7-46bd-a9cd-4c9da4e21742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".  ..  .git  README.md\ttransformer_base  vlsp-mt\n"
          ]
        }
      ],
      "source": [
        "! ls -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDIBELveLUZ5",
        "outputId": "e4d5552d-bc2d-491d-89c2-49b73133f69f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/BTL-NLP-2526I_INT3406_3/vlsp-mt\n"
          ]
        }
      ],
      "source": [
        "%cd vlsp-mt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJF_PsYCLZfa",
        "outputId": "22b11d4d-0827-4fae-b1dc-5913f3ae2bd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MinHash LSH Deduplication\n",
            "============================================================\n",
            "\n",
            "Loading data...\n",
            "Loaded 500,000 pairs\n",
            "Preparing texts for hashing...\n",
            "Building MinHash signatures (threshold=0.8, k=5)...\n",
            "Using 12 workers for parallel processing...\n",
            "Computing MinHash: 100% 500000/500000 [05:30<00:00, 1510.65it/s]\n",
            "Building LSH index...\n",
            "Indexing: 100% 500000/500000 [00:16<00:00, 29867.11it/s]\n",
            "Finding duplicate clusters...\n",
            "Clustering: 100% 500000/500000 [00:10<00:00, 49161.03it/s]\n",
            "\n",
            "============================================================\n",
            "DEDUPLICATION RESULTS\n",
            "============================================================\n",
            "  Original pairs:     500,000\n",
            "  Kept pairs:         342,789\n",
            "  Removed pairs:      157,211\n",
            "  Keep ratio:         68.56%\n",
            "  Number of clusters: 342,789\n",
            "  Avg cluster size:   1.46\n",
            "  Max cluster size:   187\n",
            "  Singleton clusters: 190,929\n",
            "============================================================\n",
            "\n",
            "Saving deduplicated data...\n",
            "  Source: data/dedup/train.en\n",
            "  Target: data/dedup/train.vi\n",
            "  Metadata: data/dedup/dedup_meta.json\n"
          ]
        }
      ],
      "source": [
        "!python scripts/dedup_minhash.py \\\n",
        "    --src data/raw/train.en.txt \\\n",
        "    --tgt data/raw/train.vi.txt \\\n",
        "    --out_dir data/dedup \\\n",
        "    --threshold 0.8 \\\n",
        "    --dedup_by both \\\n",
        "    --rep_strategy longest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHR38nUWLpE3",
        "outputId": "f98521f0-5e5f-4f45-9009-71697b837044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "VLSP Medical Translation Preprocessing\n",
            "============================================================\n",
            "\n",
            "Loading data from:\n",
            "  Source: data/dedup/train.en\n",
            "  Target: data/dedup/train.vi\n",
            "Loaded 342,789 pairs\n",
            "\n",
            "Cleaning...\n",
            "After cleaning: 342,789 pairs\n",
            "\n",
            "Filtering...\n",
            "After filtering: 334,510 pairs\n",
            "\n",
            "Deduplicating by 'both'...\n",
            "After dedup: 334,510 pairs\n",
            "\n",
            "Splitting (dev=1000, test=1000)...\n",
            "\n",
            "Train:\n",
            "  Pairs: 332,510\n",
            "  Src length: min=3, max=229, avg=21.3\n",
            "  Tgt length: min=3, max=256, avg=30.2\n",
            "\n",
            "Dev:\n",
            "  Pairs: 1,000\n",
            "  Src length: min=3, max=125, avg=21.8\n",
            "  Tgt length: min=3, max=210, avg=30.9\n",
            "\n",
            "Test:\n",
            "  Pairs: 1,000\n",
            "  Src length: min=3, max=146, avg=20.7\n",
            "  Tgt length: min=5, max=243, avg=29.3\n",
            "\n",
            "============================================================\n",
            "Preprocessing complete!\n",
            "Output saved to: data/clean\n",
            "============================================================\n",
            "Config saved to: data/clean/preprocess_config.json\n"
          ]
        }
      ],
      "source": [
        "!python scripts/preprocess_vlsp.py \\\n",
        "    --src_in data/dedup/train.en \\\n",
        "    --tgt_in data/dedup/train.vi \\\n",
        "    --out_dir data/clean \\\n",
        "    --min_len 3 \\\n",
        "    --max_len 256 \\\n",
        "    --max_ratio 3.0 \\\n",
        "    --dev_size 1000 \\\n",
        "    --test_size 1000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuSBvV2OvL_f",
        "outputId": "0037634e-bbbd-40d3-a406-a7ee040ea8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BTL-NLP-2526I_INT3406_3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrPhooiwtaWB",
        "outputId": "a0dfb5ac-ee08-41ef-c331-b705da7c2155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..  .git  README.md\ttransformer_base  vlsp-mt\n"
          ]
        }
      ],
      "source": [
        "!ls -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMCoxNXGtT_Z",
        "outputId": "a289bd00-9db7-406b-d227-f9a9e99fd956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: vlsp-mt/ (stored 0%)\n",
            "  adding: vlsp-mt/scripts/ (stored 0%)\n",
            "  adding: vlsp-mt/scripts/preprocess_vlsp.py (deflated 69%)\n",
            "  adding: vlsp-mt/scripts/dedup_minhash.py (deflated 68%)\n",
            "  adding: vlsp-mt/scripts/rl_train_grpo.py (deflated 70%)\n",
            "  adding: vlsp-mt/scripts/train_qwen_lora.py (deflated 72%)\n",
            "  adding: vlsp-mt/scripts/generate.py (deflated 70%)\n",
            "  adding: vlsp-mt/scripts/run_eval_all.py (deflated 67%)\n",
            "  adding: vlsp-mt/scripts/eval_bleu.py (deflated 68%)\n",
            "  adding: vlsp-mt/run.md (deflated 72%)\n",
            "  adding: vlsp-mt/outputs/ (stored 0%)\n",
            "  adding: vlsp-mt/outputs/dev.hyp.sft.vi (deflated 69%)\n",
            "  adding: vlsp-mt/outputs/dev.hyp.rl.vi (deflated 68%)\n",
            "  adding: vlsp-mt/runs/ (stored 0%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/ (stored 0%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/training_history.json (deflated 67%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/ (stored 0%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/training_args.bin (deflated 53%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/trainer_state.json (deflated 63%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/README.md (deflated 65%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/added_tokens.json (deflated 67%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/adapter_model.safetensors (deflated 7%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/special_tokens_map.json (deflated 69%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/tokenizer_config.json (deflated 89%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/merges.txt (deflated 57%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/scheduler.pt (deflated 61%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/chat_template.jinja (deflated 71%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/vocab.json (deflated 69%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/rng_state.pth (deflated 26%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/optimizer.pt (deflated 9%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-5195/adapter_config.json (deflated 58%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/ (stored 0%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/training_args.bin (deflated 53%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/trainer_state.json (deflated 66%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/README.md (deflated 65%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/added_tokens.json (deflated 67%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/adapter_model.safetensors (deflated 7%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/special_tokens_map.json (deflated 69%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/tokenizer_config.json (deflated 89%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/merges.txt (deflated 57%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/scheduler.pt (deflated 62%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/chat_template.jinja (deflated 71%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/vocab.json (deflated 69%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/rng_state.pth (deflated 26%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/optimizer.pt (deflated 9%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10391/adapter_config.json (deflated 58%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/meta.json (deflated 51%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/lora_en2vi_sft/ (stored 0%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/lora_en2vi_sft/README.md (deflated 65%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/lora_en2vi_sft/added_tokens.json (deflated 67%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/lora_en2vi_sft/adapter_model.safetensors (deflated 7%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/lora_en2vi_sft/special_tokens_map.json (deflated 69%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/lora_en2vi_sft/tokenizer_config.json (deflated 89%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/lora_en2vi_sft/merges.txt (deflated 57%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/lora_en2vi_sft/chat_template.jinja (deflated 71%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/lora_en2vi_sft/vocab.json (deflated 69%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/lora_en2vi_sft/adapter_config.json (deflated 58%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/ (stored 0%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/training_args.bin (deflated 53%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/trainer_state.json (deflated 67%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/README.md (deflated 65%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/added_tokens.json (deflated 67%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/adapter_model.safetensors (deflated 7%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/special_tokens_map.json (deflated 69%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/tokenizer_config.json (deflated 89%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/merges.txt (deflated 57%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/scheduler.pt (deflated 61%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/chat_template.jinja (deflated 71%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/vocab.json (deflated 69%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/rng_state.pth (deflated 26%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/optimizer.pt (deflated 9%)\n",
            "  adding: vlsp-mt/runs/qwen_fast/checkpoint-10390/adapter_config.json (deflated 58%)\n",
            "  adding: vlsp-mt/runs/qwen_rl/ (stored 0%)\n",
            "  adding: vlsp-mt/runs/qwen_rl/epoch-1/ (stored 0%)\n",
            "  adding: vlsp-mt/runs/qwen_rl/epoch-1/README.md (deflated 65%)\n",
            "  adding: vlsp-mt/runs/qwen_rl/epoch-1/adapter_model.safetensors (deflated 7%)\n",
            "  adding: vlsp-mt/runs/qwen_rl/epoch-1/adapter_config.json (deflated 58%)\n",
            "  adding: vlsp-mt/runs/qwen_rl/final_model/ (stored 0%)\n",
            "  adding: vlsp-mt/runs/qwen_rl/final_model/README.md (deflated 65%)\n",
            "  adding: vlsp-mt/runs/qwen_rl/final_model/adapter_model.safetensors (deflated 7%)\n",
            "  adding: vlsp-mt/runs/qwen_rl/final_model/adapter_config.json (deflated 58%)\n",
            "  adding: vlsp-mt/runs/qwen_fast_rl/ (stored 0%)\n",
            "  adding: vlsp-mt/runs/qwen_rl_fast/ (stored 0%)\n",
            "  adding: vlsp-mt/requirements.txt (deflated 33%)\n",
            "  adding: vlsp-mt/experiment_log.md (stored 0%)\n",
            "  adding: vlsp-mt/data/ (stored 0%)\n",
            "  adding: vlsp-mt/data/dedup/ (stored 0%)\n",
            "  adding: vlsp-mt/data/dedup/train.vi (deflated 74%)\n",
            "  adding: vlsp-mt/data/dedup/train.en (deflated 68%)\n",
            "  adding: vlsp-mt/data/dedup/dedup_meta.json (deflated 52%)\n",
            "  adding: vlsp-mt/data/raw/ (stored 0%)\n",
            "  adding: vlsp-mt/data/raw/public_test.en.txt (deflated 64%)\n",
            "  adding: vlsp-mt/data/raw/train.vi.txt (deflated 72%)\n",
            "  adding: vlsp-mt/data/raw/public_test.vi.txt (deflated 71%)\n",
            "  adding: vlsp-mt/data/raw/train.en.txt (deflated 66%)\n",
            "  adding: vlsp-mt/data/clean/ (stored 0%)\n",
            "  adding: vlsp-mt/data/clean/train.vi (deflated 68%)\n",
            "  adding: vlsp-mt/data/clean/dev.en (deflated 60%)\n",
            "  adding: vlsp-mt/data/clean/test.vi (deflated 67%)\n",
            "  adding: vlsp-mt/data/clean/preprocess_config.json (deflated 49%)\n",
            "  adding: vlsp-mt/data/clean/test.en (deflated 60%)\n",
            "  adding: vlsp-mt/data/clean/train.en (deflated 61%)\n",
            "  adding: vlsp-mt/data/clean/dev.vi (deflated 67%)\n",
            "  adding: vlsp-mt/data/rl_subset/ (stored 0%)\n",
            "  adding: vlsp-mt/data/rl_subset/en.txt (deflated 61%)\n",
            "  adding: vlsp-mt/data/rl_subset/vi.txt (deflated 68%)\n"
          ]
        }
      ],
      "source": [
        "# 1. Nén thư mục 'vlsp-mt/data' thành file 'data_backup.zip'\n",
        "\n",
        "!zip -r data_backup.zip vlsp-mt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "DYKtQfhjtfTn",
        "outputId": "67025ca9-d8f6-4d5d-8487-f61f18378423"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e1ceb88d-d3c0-4d52-958a-23cc0d80912d\", \"data_backup.zip\", 2771642774)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 2. Tải file zip về máy\n",
        "from google.colab import files\n",
        "files.download('data_backup.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h9AV-Z2L4gq",
        "outputId": "b832a5a6-dd94-4286-91e2-259912c35ed3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 16M\n",
            "-rw-r--r-- 1 root root 6.9M Dec 15 08:45 en.txt\n",
            "-rw-r--r-- 1 root root 8.7M Dec 15 08:45 vi.txt\n"
          ]
        }
      ],
      "source": [
        "# 1. Tạo thư mục đích trước\n",
        "!mkdir -p data/rl_subset\n",
        "\n",
        "# 2. Chạy lệnh cắt file\n",
        "!head -n 50000 data/clean/train.en > data/rl_subset/en.txt\n",
        "!head -n 50000 data/clean/train.vi > data/rl_subset/vi.txt\n",
        "\n",
        "!ls -lh data/rl_subset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFkkMbgJMSlh",
        "outputId": "a58ca736-0616-4adb-d767-62fff3114031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-15 08:45:46.803670: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-15 08:45:46.821753: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765788346.843772    3066 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765788346.850277    3066 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765788346.866815    3066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765788346.866845    3066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765788346.866848    3066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765788346.866851    3066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-15 08:45:46.871854: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading tokenizer: Qwen/Qwen2.5-3B-Instruct\n",
            "tokenizer_config.json: 7.30kB [00:00, 22.9MB/s]\n",
            "vocab.json: 2.78MB [00:00, 124MB/s]\n",
            "merges.txt: 1.67MB [00:00, 138MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 180MB/s]\n",
            "Loading model: Qwen/Qwen2.5-3B-Instruct\n",
            "Using dtype: torch.bfloat16\n",
            "Flash Attention not installed, using SDPA\n",
            "config.json: 100% 661/661 [00:00<00:00, 6.23MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors.index.json: 35.6kB [00:00, 93.8MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/3.97G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/2.20G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 866k/2.20G [00:01<1:13:32, 499kB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   2% 36.5M/2.20G [00:01<01:19, 27.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 20.3k/3.97G [00:02<117:28:50, 9.38kB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   3% 64.4M/2.20G [00:02<00:45, 47.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 40.5M/3.97G [00:02<02:38, 24.7MB/s]    \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   6% 123M/2.20G [00:02<00:19, 105MB/s]  \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 66.2M/3.97G [00:02<01:44, 37.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 84.7M/3.97G [00:02<01:23, 46.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 123M/3.97G [00:02<00:48, 80.1MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   9% 190M/2.20G [00:02<00:17, 115MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 197M/3.97G [00:03<00:22, 165MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  26% 562M/2.20G [00:02<00:03, 493MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 316M/3.97G [00:03<00:11, 322MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 380M/3.97G [00:03<00:09, 362MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  31% 680M/2.20G [00:03<00:03, 504MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 445M/3.97G [00:03<00:08, 402MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  36% 791M/2.20G [00:03<00:02, 480MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  39% 868M/2.20G [00:03<00:02, 493MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  45% 992M/2.20G [00:03<00:02, 579MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 563M/3.97G [00:03<00:10, 316MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 942M/3.97G [00:03<00:03, 770MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  49% 1.09G/2.20G [00:03<00:02, 496MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.11G/3.97G [00:04<00:03, 850MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.26G/3.97G [00:04<00:02, 926MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  53% 1.16G/2.20G [00:04<00:02, 447MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  61% 1.34G/2.20G [00:04<00:01, 651MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.39G/3.97G [00:04<00:02, 882MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  66% 1.46G/2.20G [00:04<00:01, 623MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.55G/3.97G [00:04<00:03, 795MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 1.69G/3.97G [00:05<00:03, 615MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 1.85G/3.97G [00:05<00:02, 750MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.00G/3.97G [00:05<00:02, 841MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  72% 1.59G/2.20G [00:05<00:01, 351MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.11G/3.97G [00:05<00:02, 807MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.23G/3.97G [00:05<00:03, 482MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  75% 1.66G/2.20G [00:05<00:02, 238MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.31G/3.97G [00:06<00:05, 315MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.40G/3.97G [00:06<00:05, 308MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 2.60G/3.97G [00:07<00:03, 446MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 2.70G/3.97G [00:07<00:04, 309MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 2.79G/3.97G [00:08<00:04, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 2.85G/3.97G [00:08<00:05, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 2.92G/3.97G [00:09<00:05, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 2.98G/3.97G [00:09<00:05, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.05G/3.97G [00:10<00:05, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.09G/3.97G [00:10<00:04, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.12G/3.97G [00:10<00:04, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.19G/3.97G [00:10<00:03, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 3.31G/3.97G [00:10<00:01, 331MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 3.45G/3.97G [00:10<00:01, 452MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 3.51G/3.97G [00:11<00:01, 403MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 3.65G/3.97G [00:11<00:00, 512MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 3.73G/3.97G [00:11<00:00, 305MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 3.79G/3.97G [00:12<00:00, 324MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 3.84G/3.97G [00:12<00:00, 251MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  79% 1.73G/2.20G [00:12<00:11, 41.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 3.97G/3.97G [00:12<00:00, 310MB/s]\n",
            "Fetching 2 files:  50% 1/2 [00:13<00:13, 13.31s/it]\n",
            "\n",
            "model-00002-of-00002.safetensors:  80% 1.77G/2.20G [00:12<00:09, 46.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  83% 1.84G/2.20G [00:13<00:06, 59.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  86% 1.90G/2.20G [00:13<00:03, 77.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  89% 1.97G/2.20G [00:13<00:02, 101MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  92% 2.04G/2.20G [00:13<00:01, 129MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  96% 2.11G/2.20G [00:13<00:00, 166MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 2.20G/2.20G [00:13<00:00, 159MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:14<00:00,  7.28s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.02it/s]\n",
            "generation_config.json: 100% 242/242 [00:00<00:00, 2.04MB/s]\n",
            "Gradient checkpointing DISABLED (faster but more VRAM)\n",
            "Trainable params: 59,867,136 (1.90%)\n",
            "Loading training data...\n",
            "Training samples: 332510\n",
            "Tokenizing train: 100% 332510/332510 [05:42<00:00, 970.75 examples/s] \n",
            "Effective batch size: 32\n",
            "Steps per epoch: 10390\n",
            "Total steps: 10390\n",
            "/content/BTL-NLP-2526I_INT3406_3/vlsp-mt/scripts/train_qwen_lora.py:431: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(**trainer_kwargs)\n",
            "\n",
            "============================================================\n",
            "Starting training...\n",
            "============================================================\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "{'loss': 1.9775, 'grad_norm': 19.442949295043945, 'learning_rate': 0.0, 'epoch': 0.0}\n",
            "{'loss': 1.0638, 'grad_norm': 2.3506968021392822, 'learning_rate': 0.00019961538461538462, 'epoch': 0.1}\n",
            "{'loss': 1.0034, 'grad_norm': 2.8943960666656494, 'learning_rate': 0.00019399222210599048, 'epoch': 0.2}\n",
            "{'loss': 0.9555, 'grad_norm': 3.312070369720459, 'learning_rate': 0.00017664761762280334, 'epoch': 0.3}\n",
            "{'loss': 0.9246, 'grad_norm': 2.7411439418792725, 'learning_rate': 0.00015005817925594603, 'epoch': 0.4}\n",
            "{'loss': 0.9478, 'grad_norm': 2.8640284538269043, 'learning_rate': 0.00011743098569077804, 'epoch': 0.5}\n",
            "{'loss': 0.8361, 'grad_norm': 2.6517140865325928, 'learning_rate': 8.270135799735184e-05, 'epoch': 0.6}\n",
            "{'loss': 0.7952, 'grad_norm': 2.4537739753723145, 'learning_rate': 5.005820183021059e-05, 'epoch': 0.7}\n",
            "{'loss': 0.7592, 'grad_norm': 2.4719226360321045, 'learning_rate': 2.3438763584787605e-05, 'epoch': 0.8}\n",
            "{'loss': 0.7344, 'grad_norm': 2.318230152130127, 'learning_rate': 6.053740374548478e-06, 'epoch': 0.9}\n",
            "{'loss': 0.7296, 'grad_norm': 1.942037582397461, 'learning_rate': 2.2574264568753222e-11, 'epoch': 1.0}\n",
            "{'train_runtime': 11457.6044, 'train_samples_per_second': 29.021, 'train_steps_per_second': 0.907, 'train_loss': 0.875027601063372, 'epoch': 1.0}\n",
            "100% 10391/10391 [3:10:57<00:00,  1.10s/it]\n",
            "\n",
            "Saving adapter to runs/qwen_fast/lora_en2vi_sft\n",
            "\n",
            "============================================================\n",
            "Training complete!\n",
            "Adapter saved to: runs/qwen_fast/lora_en2vi_sft\n",
            "Metadata saved to: runs/qwen_fast/meta.json\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "!python scripts/train_qwen_lora.py \\\n",
        "    --model_name Qwen/Qwen2.5-3B-Instruct \\\n",
        "    --direction en2vi \\\n",
        "    --src data/clean/train.en \\\n",
        "    --tgt data/clean/train.vi \\\n",
        "    --run_id qwen_fast \\\n",
        "    --batch_size 32 \\\n",
        "    --grad_accum 1 \\\n",
        "    --epochs 1 \\\n",
        "    --neftune_alpha 0 \\\n",
        "    --no_grad_checkpoint \\\n",
        "    --label_smoothing 0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 10000 data/clean/train.en > data/rl_subset/en.txt\n",
        "!head -n 10000 data/clean/train.vi > data/rl_subset/vi.txt"
      ],
      "metadata": {
        "id": "5Fo0nqev7y7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKL8a2LJMeGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242caa92-94bb-49f0-ab09-1074e6453c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-15 12:15:22.432700: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-15 12:15:22.452392: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765800922.475129   54614 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765800922.481866   54614 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765800922.499311   54614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765800922.499361   54614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765800922.499364   54614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765800922.499367   54614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-15 12:15:22.504477: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Using device: cuda\n",
            "Using SDPA\n",
            "Loading base model...\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.05it/s]\n",
            "Loading SFT adapter...\n",
            "Loading trainable model...\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.05it/s]\n",
            "Trainable params: 59,867,136\n",
            "Loaded RL data: 10000 pairs\n",
            "Epoch 1/1:   0% 0/625 [00:00<?, ?it/s]/content/BTL-NLP-2526I_INT3406_3/vlsp-mt/scripts/rl_train_grpo.py:77: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
            "Epoch 1/1: 100% 625/625 [2:14:56<00:00, 12.95s/it, loss=-0.6264, reward=0.4779, baseline=0.4875]\n",
            "\n",
            "Epoch 1 avg reward: 0.4894\n",
            "\n",
            "RL training completed!\n"
          ]
        }
      ],
      "source": [
        "!python scripts/rl_train_grpo.py \\\n",
        "    --model_name Qwen/Qwen2.5-3B-Instruct \\\n",
        "    --sft_adapter runs/qwen_fast/lora_en2vi_sft \\\n",
        "    --init_adapter runs/qwen_fast/lora_en2vi_sft \\\n",
        "    --rl_src data/rl_subset/en.txt \\\n",
        "    --rl_tgt data/rl_subset/vi.txt \\\n",
        "    --run_id qwen_rl \\\n",
        "    --direction en2vi \\\n",
        "    --batch_size 16 \\\n",
        "    --max_new_tokens 48"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReGWjQNvMkeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4abbb893-a38d-4ade-a853-489db09748bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-15 15:03:02.885671: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-15 15:03:02.904220: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765810982.926718   96287 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765810982.933361   96287 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765810982.950247   96287 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765810982.950297   96287 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765810982.950300   96287 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765810982.950302   96287 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-15 15:03:02.955315: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading model: Qwen/Qwen2.5-3B-Instruct\n",
            "Loading adapter: runs/qwen_fast/lora_en2vi_sft\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.04it/s]\n",
            "Model loaded on cuda:0, dtype=torch.bfloat16\n",
            "Loaded 1000 sentences from data/clean/dev.en\n",
            "Generating:   0% 0/125 [00:00<?, ?it/s]/content/BTL-NLP-2526I_INT3406_3/vlsp-mt/scripts/generate.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Generating: 100% 125/125 [19:23<00:00,  9.31s/it]\n",
            "\n",
            "Saved 1000 translations to outputs/dev.hyp.sft.vi\n"
          ]
        }
      ],
      "source": [
        "!python scripts/generate.py \\\n",
        "    --model_name Qwen/Qwen2.5-3B-Instruct \\\n",
        "    --adapter_path runs/qwen_fast/lora_en2vi_sft \\\n",
        "    --direction en2vi \\\n",
        "    --input data/clean/dev.en \\\n",
        "    --output outputs/dev.hyp.sft.vi \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/generate.py \\\n",
        "    --model_name Qwen/Qwen2.5-3B-Instruct \\\n",
        "    --adapter_path runs/qwen_rl/final_model \\\n",
        "    --direction en2vi \\\n",
        "    --input data/clean/dev.en \\\n",
        "    --output outputs/dev.hyp.rl.vi \\\n",
        "    --batch_size 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgmtQ7pinvLE",
        "outputId": "f377601c-8505-41cd-bb5f-72e2318b0cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-15 15:27:00.768243: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-15 15:27:00.786652: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765812420.808712  102245 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765812420.815192  102245 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765812420.831986  102245 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765812420.832034  102245 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765812420.832037  102245 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765812420.832040  102245 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-15 15:27:00.836958: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading model: Qwen/Qwen2.5-3B-Instruct\n",
            "Loading adapter: runs/qwen_rl/final_model\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.04it/s]\n",
            "Model loaded on cuda:0, dtype=torch.bfloat16\n",
            "Loaded 1000 sentences from data/clean/dev.en\n",
            "Generating:   0% 0/125 [00:00<?, ?it/s]/content/BTL-NLP-2526I_INT3406_3/vlsp-mt/scripts/generate.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Generating: 100% 125/125 [19:43<00:00,  9.47s/it]\n",
            "\n",
            "Saved 1000 translations to outputs/dev.hyp.rl.vi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcesgjccMs5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d672d7c2-c823-465a-a1a1-c24899c3dba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading hypothesis: outputs/dev.hyp.sft.vi\n",
            "Loading reference: data/clean/dev.vi\n",
            "\n",
            "Evaluating 1000 sentence pairs...\n",
            "\n",
            "==================================================\n",
            "EVALUATION RESULTS\n",
            "==================================================\n",
            "  BLEU:    49.84\n",
            "  chrF++:  64.40\n",
            "  chrF:    64.52\n",
            "  TER:     42.31 (lower is better)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "!python scripts/eval_bleu.py \\\n",
        "    --hyp outputs/dev.hyp.sft.vi \\\n",
        "    --ref data/clean/dev.vi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/eval_bleu.py --hyp outputs/dev.hyp.rl.vi --ref data/clean/dev.vi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWcpwrassot5",
        "outputId": "e4cdbc66-6d97-4752-d47f-90ab2383b393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading hypothesis: outputs/dev.hyp.rl.vi\n",
            "Loading reference: data/clean/dev.vi\n",
            "\n",
            "Evaluating 1000 sentence pairs...\n",
            "\n",
            "==================================================\n",
            "EVALUATION RESULTS\n",
            "==================================================\n",
            "  BLEU:    50.09\n",
            "  chrF++:  64.65\n",
            "  chrF:    64.78\n",
            "  TER:     42.28 (lower is better)\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHD4t55Iz6Ab"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}